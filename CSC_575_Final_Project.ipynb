{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0adf52",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> CSC 575 Final Project</h2>\n",
    "<h2 align=\"center\">NAWAAZ SHARIF</h2> \n",
    "<h2 align=\"center\">MOHAMMED RASHIDUDDIN</h2> \n",
    "<h2 align=\"center\">SYED NOOR RAZI ALI</h2> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8f8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the reuqired packages and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from IPython.display import Image\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "import itertools\n",
    "import zipfile\n",
    "import math\n",
    "import xml.etree.ElementTree as ET\n",
    "import urllib.request\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import snowball\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "stopwords = set(stopwords.words('english'))\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a30bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the GoogleNews-vectors-negative module for Word2vec to expand the query.\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(r'GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628335e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining all the zip files to a single zip.\n",
    "\n",
    "zipfile_names = ['ClinicalTrials.2021-04-27.part1.zip', 'ClinicalTrials.2021-04-27.part5.zip', 'ClinicalTrials.2021-04-27.part2.zip' , 'ClinicalTrials.2021-04-27.part3.zip' , 'ClinicalTrials.2021-04-27.part4.zip']\n",
    "\n",
    "# Create a new zip file to store the combined contents\n",
    "combined_zipfile = zipfile.ZipFile('Final_combined_ClinicalTrials.zip', 'w')\n",
    "\n",
    "# Loop through each zip file and add its contents to the combined zip file\n",
    "for filename in zipfile_names:\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        for member in zip_ref.infolist():\n",
    "            combined_zipfile.writestr(member.filename, zip_ref.read(member.filename))\n",
    "\n",
    "combined_zipfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d3c8bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Reading the files from the XML to get the required ID and the context of the document\n",
    "df_clinical_trial = pd.DataFrame(columns=['org_study_id', 'nct_id', 'brief_title', 'sponsor_agency', 'brief_summary' ,'detailed_description' , 'condition' , 'eligibility_condition' , 'eligibility_gender' , 'eligibility_minage' , 'eligibility_maxage'] , dtype=object)\n",
    "with zipfile.ZipFile(r'Final_combined_ClinicalTrials.zip', 'r') as zip_ref:\n",
    "    xml_files = [f for f in zip_ref.namelist() if f.endswith('.xml')]\n",
    "    #considering only 1000 xml files.\n",
    "    for xml_file in xml_files[0:10]:\n",
    "        #extracting the zip\n",
    "        zip_ref.extract(xml_file, path='temp')\n",
    "        #parsing to read the contents\n",
    "        tree = ET.parse(f'temp/{xml_file}')\n",
    "        root = tree.getroot()\n",
    "        #Orginization Study ID\n",
    "        org_study_id = root.find('id_info/org_study_id').text if root.find('id_info/org_study_id') is not None else ''\n",
    "        #Document ID\n",
    "        nct_id = root.find('id_info/nct_id').text.replace('NCT00', 'D').strip() if root.find('id_info/nct_id') is not None else ''\n",
    "        #Brief Title of the document\n",
    "        brief_title = root.find('brief_title').text if root.find('brief_title') is not None else ''\n",
    "        sponsor_agency = root.find('sponsors/lead_sponsor/agency').text if root.find('sponsors/lead_sponsor/agency') is not None else ''\n",
    "        #Brief Summary of Clinical Trials\n",
    "        brief_summary = root.find('brief_summary/textblock').text.replace('\\n', ' ').replace('\\r', ' ').strip() if root.find('brief_summary/textblock') is not None else ''\n",
    "        #Detailed Description of Clinical Trial\n",
    "        detailed_description = root.find('detailed_description/textblock').text.replace('\\n', ' ').replace('\\r', ' ').strip() if root.find('detailed_description/textblock')is not None else ''\n",
    "        condition = root.find('condition').text if root.find('condition') is not None else ''\n",
    "        eligibility_condition = root.find('eligibility/criteria/textblock').text.replace('\\n', ' ').replace('\\r', ' ').strip() if root.find('eligibility/criteria/textblock') is not None else ''\n",
    "        eligibility_gender = root.find('eligibility/gender').text if root.find('eligibility/gender') is not None else ''\n",
    "        eligibility_minage = root.find('eligibility/minimum_age').text if root.find('eligibility/minimum_age') is not None else ''\n",
    "        eligibility_maxage = root.find('eligibility/maximum_age').text if root.find('eligibility/maximum_age') is not None else ''\n",
    "        df_clinical_trial.loc[len(df_clinical_trial.index)] =[org_study_id, nct_id, brief_title, sponsor_agency, brief_summary ,detailed_description , condition , eligibility_condition , eligibility_gender , eligibility_minage , eligibility_maxage]\n",
    "# print(df_clinical_trial)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa7b1efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_study_id</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>sponsor_agency</th>\n",
       "      <th>brief_summary</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>condition</th>\n",
       "      <th>eligibility_condition</th>\n",
       "      <th>eligibility_gender</th>\n",
       "      <th>eligibility_minage</th>\n",
       "      <th>eligibility_maxage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCRR-M01RR01070-0506</td>\n",
       "      <td>D000102</td>\n",
       "      <td>Congenital Adrenal Hyperplasia: Calcium Channe...</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>This study will test the ability of extended r...</td>\n",
       "      <td>This protocol is designed to assess both acute...</td>\n",
       "      <td>Congenital Adrenal Hyperplasia</td>\n",
       "      <td>Inclusion Criteria:              -  diagnosed ...</td>\n",
       "      <td>All</td>\n",
       "      <td>14 Years</td>\n",
       "      <td>35 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCRR-M01RR00400-0587</td>\n",
       "      <td>D000104</td>\n",
       "      <td>Does Lead Burden Alter Neuropsychological Deve...</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>Inner city children are at an increased risk f...</td>\n",
       "      <td></td>\n",
       "      <td>Lead Poisoning</td>\n",
       "      <td>Inclusion Criteria:              -  Pregnant m...</td>\n",
       "      <td>Female</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002LS032</td>\n",
       "      <td>D000105</td>\n",
       "      <td>Vaccination With Tetanus and KLH to Assess Imm...</td>\n",
       "      <td>Masonic Cancer Center, University of Minnesota</td>\n",
       "      <td>The purpose of this study is to learn how the ...</td>\n",
       "      <td>Patients will receive each vaccine once only c...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Inclusion Criteria:              -  Patients m...</td>\n",
       "      <td>All</td>\n",
       "      <td>18 Years</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCRR-M01RR03186-9943</td>\n",
       "      <td>D000106</td>\n",
       "      <td>41.8 Degree Centigrade Whole Body Hyperthermia...</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>Recently a non-toxic system for whole body hyp...</td>\n",
       "      <td></td>\n",
       "      <td>Rheumatic Diseases</td>\n",
       "      <td>Inclusion Criteria:              -  Patients a...</td>\n",
       "      <td>All</td>\n",
       "      <td>18 Years</td>\n",
       "      <td>65 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCRR-M01RR00109-0737</td>\n",
       "      <td>D000107</td>\n",
       "      <td>Body Water Content in Cyanotic Congenital Hear...</td>\n",
       "      <td>National Center for Research Resources (NCRR)</td>\n",
       "      <td>Adults with cyanotic congenital heart disease ...</td>\n",
       "      <td></td>\n",
       "      <td>Heart Defects, Congenital</td>\n",
       "      <td>Inclusion Criteria:              -  Resting bl...</td>\n",
       "      <td>All</td>\n",
       "      <td>17 Years</td>\n",
       "      <td>60 Years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           org_study_id   nct_id  \\\n",
       "0  NCRR-M01RR01070-0506  D000102   \n",
       "1  NCRR-M01RR00400-0587  D000104   \n",
       "2             2002LS032  D000105   \n",
       "3  NCRR-M01RR03186-9943  D000106   \n",
       "4  NCRR-M01RR00109-0737  D000107   \n",
       "\n",
       "                                         brief_title  \\\n",
       "0  Congenital Adrenal Hyperplasia: Calcium Channe...   \n",
       "1  Does Lead Burden Alter Neuropsychological Deve...   \n",
       "2  Vaccination With Tetanus and KLH to Assess Imm...   \n",
       "3  41.8 Degree Centigrade Whole Body Hyperthermia...   \n",
       "4  Body Water Content in Cyanotic Congenital Hear...   \n",
       "\n",
       "                                   sponsor_agency  \\\n",
       "0   National Center for Research Resources (NCRR)   \n",
       "1   National Center for Research Resources (NCRR)   \n",
       "2  Masonic Cancer Center, University of Minnesota   \n",
       "3   National Center for Research Resources (NCRR)   \n",
       "4   National Center for Research Resources (NCRR)   \n",
       "\n",
       "                                       brief_summary  \\\n",
       "0  This study will test the ability of extended r...   \n",
       "1  Inner city children are at an increased risk f...   \n",
       "2  The purpose of this study is to learn how the ...   \n",
       "3  Recently a non-toxic system for whole body hyp...   \n",
       "4  Adults with cyanotic congenital heart disease ...   \n",
       "\n",
       "                                detailed_description  \\\n",
       "0  This protocol is designed to assess both acute...   \n",
       "1                                                      \n",
       "2  Patients will receive each vaccine once only c...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                        condition  \\\n",
       "0  Congenital Adrenal Hyperplasia   \n",
       "1                  Lead Poisoning   \n",
       "2                          Cancer   \n",
       "3              Rheumatic Diseases   \n",
       "4       Heart Defects, Congenital   \n",
       "\n",
       "                               eligibility_condition eligibility_gender  \\\n",
       "0  Inclusion Criteria:              -  diagnosed ...                All   \n",
       "1  Inclusion Criteria:              -  Pregnant m...             Female   \n",
       "2  Inclusion Criteria:              -  Patients m...                All   \n",
       "3  Inclusion Criteria:              -  Patients a...                All   \n",
       "4  Inclusion Criteria:              -  Resting bl...                All   \n",
       "\n",
       "  eligibility_minage eligibility_maxage  \n",
       "0           14 Years           35 Years  \n",
       "1                N/A                N/A  \n",
       "2           18 Years                N/A  \n",
       "3           18 Years           65 Years  \n",
       "4           17 Years           60 Years  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clinical_trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f0e03c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clinical_trial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca6de30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D000102': 'This protocol is designed to assess both acute and chronic effects of the calcium channel        antagonist, nifedipine, on the hypothalamic-pituitary-adrenal axis in patients with        congenital adrenal hyperplasia. The multicenter trial is composed of two phases and will        involve a double-blind, placebo-controlled parallel design. The goal of Phase I is to examine        the ability of nifedipine vs. placebo to decrease adrenocorticotropic hormone (ACTH) levels,        as well as to begin to assess the dose-dependency of nifedipine effects. The goal of Phase II        is to evaluate the long-term effects of nifedipine; that is, can attenuation of ACTH release        by nifedipine permit a decrease in the dosage of glucocorticoid needed to suppress the HPA        axis? Such a decrease would, in turn, reduce the deleterious effects of glucocorticoid        treatment in CAH._Congenital Adrenal Hyperplasia: Calcium Channels as Therapeutic Targets_This study will test the ability of extended release nifedipine (Procardia XL), a blood        pressure medication, to permit a decrease in the dose of glucocorticoid medication children        take to treat congenital adrenal hyperplasia (CAH)._Inclusion Criteria:              -  diagnosed with Congenital Adrenal Hyperplasia (CAH)              -  normal ECG during baseline evaluation            Exclusion Criteria:              -  history of liver disease, or elevated liver function tests              -  history of cardiovascular disease_Congenital Adrenal Hyperplasia',\n",
       " 'D000104': '_Does Lead Burden Alter Neuropsychological Development?_Inner city children are at an increased risk for lead overburden. This in turn affects        cognitive functioning. However, the underlying neuropsychological effects of lead overburden        and its age-specific effects have not been well delineated. This study is part of a larger        study on the effects of lead overburden on the development of attention and memory. The        larger study is using a multi-model approach to study the effects of lead overburden on these        effects including the event-related potential (ERP), electrophysiologic measures of attention        and memory are studied. Every eight months, for a total of three sessions the subjects will        complete ERP measures of attention and memory which require them to watch various computer        images while wearing scalp electrodes recording from 11 sites. It is this test that we are        going to be doing on CRC. There will be 30 lead overburdened children recruited from the        larger study for participation in the ERP studies on CRC. These 30 children will be matched        with 30 children without lead overburden. This portion of the study is important in providing        an index of physiological functioning to be used along with behaviorally based measures of        attention and memory, and for providing information about the different measures._Inclusion Criteria:              -  Pregnant mothers of the Phillips neighborhood in Minneapolis, Minnesota. Subject               recruitment will take place in local clinics which serve pregnant women and offspring_Lead Poisoning',\n",
       " 'D000105': 'Patients will receive each vaccine once only consisting of:          Arm A: Intracel KLH 1000 mcg (1 mg) without adjuvant, subcutaneous Tetanus Toxoid 0.5 ml        intramuscularly (this arm closed 1/2/02).          Arm B: Biosyn KLH 1000 mcg (1 mg) without adjuvant, subcutaneous tetanus toxoid 0.5 ml        intramuscularly (this arm closed 3/18/03).          Arm C: Biosyn KLH 1000 mcg (1 mg) with Montanide ISA51 (now replaced with vegetable (VG)        source after 8/31/06 to increase product safety) subcutaneous Tetanus toxoid 0.5 ml        intramuscularly (this arm open 3/18/03).          Subjects ineligible for tetanus may still receive KLH on this protocol. This is especially        true given the national shortage of tetanus vaccines. Subjects will be eligible for tetanus        when it becomes available if there has been no significant change in treatment interventions        or overall health status and it is within 3 months of the KLH vaccine._Vaccination With Tetanus and KLH to Assess Immune Responses._The purpose of this study is to learn how the immune system works in response to vaccines. We        will give the vaccines to subjects who have cancer but have not had treatment, and to        patients who have had chemotherapy or stem cell transplant. Some patients will get vaccines        while they are on treatments which boost the immune system (like the immune stimulating drug        interleukin-2 or IL-2). Although we have safely treated many patients with immune boosting        drugs, we do not yet know if they improve the body\\'s immune system to respond better to a        vaccine. Some healthy volunteers will also be given the vaccines in order to serve as control        subjects to get a good measure of the normal immune response. We will compare the patients        and the healthy volunteers to study how their immune systems respond to the vaccines.          There are several different types of white cells in the blood. We are interested in immune        cells in the blood called T-cells. These T-cells detect foreign substances in the body (like        viruses and cancer cells). We are trying to learn more about how the body fights these        foreign substances. Our goal is to develop cancer vaccines which would teach T-cells to        detect and kill cancer cells better. We know that in healthy people the immune system        effectively protects against recurrent virus infection. For example, that is why people only        get \"mono\" (mononucleosis) once under normal circumstances. When the body is infected with        the \"mono\" virus, the immune system remembers and prevents further infection. We are trying        to use the immune system to prevent cancer relapse. To test this, we will give two vaccines        which have been used to measure these immune responses. Blood samples will be studied from        cancer patients and will be compared to similar samples from normal subjects._Inclusion Criteria:              -  Patients must have a diagnosis of cancer of any histologic type.              -  Patients must have a Karnofsky performance status great or equal to 70%.              -  Patients must have an expected survival for at least four months.              -  Normal healthy volunteers to serve as control for this study.              -  All patients must sign informed consent approved by the Committee on the Use of Human               Subjects at the University of Minnesota            Exclusion Criteria:              -  Pregnant or lactating women. Females of child-bearing potential will be asked to take               a pregnancy test before receiving vaccines.              -  Serious intercurrent medical illnesses which would interfere with the ability of the               patient to carry out the follow-up monitoring program.              -  Immunization should not be administered during the course of any febrile illness or               acute infection.              -  Hypersensitivity to any component of the vaccine, including Thimerosal, a mercury               derivative.              -  The occurrence of any type of neurologic symptoms to tetanus vaccine in th past.              -  Patients with a history of seafood allergy are excluded from receiving KLH.              -  Subjects who have had tetanus toxoid within the last 7 years are not eligible for               tetanus vaccine component of this protocol._Cancer',\n",
       " 'D000106': '_41.8 Degree Centigrade Whole Body Hyperthermia for the Treatment of Rheumatoid Diseases_Recently a non-toxic system for whole body hyperthermia (WBH) used at the University of        Wisconsin has been shown to induce soluble tumor necrosis factor-receptor (sTNF-R) I and II        when patients are heated systemically to 41.8C for 60 minutes. This observation might provide        a biological basis for the therapeutic application of WBH to rheumatoid diseases, for which        there is a positive anecdotal clinical experience. Inherent in the hypothesis which is the        basis for this protocol is the concept that the induction of TNF receptors by WBH may induce        a remission in patients with active rheumatoid arthritis. Beyond clinical response the        biological endpoint for this investigation includes cytokine levels, TNF levels, sTNF-R        levels and changes in cellular TNF receptors._Inclusion Criteria:              -  Patients are required to meet the criteria of the American College of Rheumatology               (ACR)for rheumatoid arthritis.              -  Patients should be in functional class II, or III according to the criteria of the               ACR.              -  All candidates must be unsuccessfully treated (lack of efficacy) with at least two of               the following disease-modifying antirheumatic drugs: hydroxychloroquinine, oral or               injectable gold, methotrexate, azathioprine, penicillamine, and sulfasalazine.              -  Patients receiving nonsteroidal antiinflammatory drugs (NSAIDs), corticosteroids (<=               10 mg per day), or both are eligible if the dosage has been stable for at least four               weeks before treatment and remained so throughout the study and follow-up period (the               use of narcotics for pain flares is allowed).              -  The necessary degree of disease activity at enrollment should be confirmed by a               finding of 10 or more swollen joints, 12 or more tender joints, and one of the               following two criteria: a Westergren erythrocyte sedimentation rate of at least 28 mm               per hour or a serum C-reactive protein level of more than 2.0 mg per deciliter; or               morning stiffness for at least 60 minutes.              -  Patients must have adequate bone marrow function, adequate liver function, adequate               renal function, calcium and electrolytes.              -  Patients must have a dobutamine stress ECHO, or exercise cardiac MUGA, or exercise               ECHO scan prior to entry and must fulfill certain criteria to be eligible. The spirit               of the criteria are to rule out organic heart disease.              -  Respiratory status: Patients who have FEV1 of >= 60% of predicted, as well as a               maximum voluntary volume (MVV) of >= 60% of predicted, and blood gases with a PO2 of               >= 60 or oxygen saturation of >= 90% are eligible._Rheumatic Diseases',\n",
       " 'D000107': \"_Body Water Content in Cyanotic Congenital Heart Disease_Adults with cyanotic congenital heart disease have elevated levels of plasma proatrial        natruretic peptide (proANP) which most likely results in chronic dehydration, leading to        reduced oxygen transport to tissues and shortness of breath with activity. The purpose of        this study is to characterize adults with cyanotic congenital heart defects with respect to        their body composition (water and fat-free mass) and resting metabolic rates. The study        consists of several measures of how much body water, fat and lean tissue a subject has, and        measures the number of calories the subject's body uses at rest. Adult subjects with cyanotic        congenital heart disease will be recruited along with healthy noncyanotic control subjects        matched for age, gender, and body weight._Inclusion Criteria:              -  Resting blood pressure below 140/90_Heart Defects, Congenital\",\n",
       " 'D000108': '_Effects of Training Intensity on the CHD Risk Factors in Postmenopausal Women_The purpose of this research is to find out whether training at different exercise        intensities reduces the risk of developing cardiovascular disease (CVD) to a different        extent. Heart attacks and stroke are the leading cause of death in older women. Reduced        variability of the heart rate and increased dips and swings in blood pressure are risks        factors that predict the chance of developing CVD as are increased levels of clotting protein        fibrinogen and plasminogen activator inhibitor 1, and high levels of LDL-cholesterol        (>160mg/dl). We will be measuring all of these risk factors and any changes in your body fat        level before you start training and after 15 and 30 weeks of training in the form of walking.        At the present time the effects of exercise intensity on these factors are not well        understood. This study will add to the basic understanding of these issues and allow us to        recommend to postmenopausal women optimal exercise intensities to lose body fat and reduce        the risk of developing CVD._Inclusion Criteria:              -  Postmenopausal and preferably on hormone replacement therapy              -  In good general health              -  Have a body mass index (BMI, weight in kg/height in m2) of between 25 and 40              -  Exercise less than 20 min/day two days a week_Cardiovascular Diseases',\n",
       " 'D000110': '_Influence of Diet and Endurance Running on Intramuscular Lipids Measured at 4.1 TESLA_The purpose of this pilot investigation is to use 1 H Magnetic Resonance Spectroscopy (MRS)        to 1) document the change in intra-muscular lipid stores (IML) before and after a prolonged        bout of endurance running and, 2) determine the pattern (time course) of IML replenishment        following an extremely low-fat diet (10% of energy from fat) and a moderate-fat diet (35% of        energy from fat). Specifically, the study will evaluate the change in IML following a 2-hour        training run and the recovery of IML in response to the post-exercise low-fat or moderate-fat        diet in 10 endurance trained athletes who will consume both diets in a randomly assigned        cross-over fashion. We hypothesize that IML will be depleted with prolonged endurance        exercise, and that replenishment of IML will be impaired by an extremely low-fat diet        compared to a moderate-fat diet. Results of this pilot study will be used to apply for        extramural grant support from NIH or the US Armed Forces to investigate the effect of dietary        fat on the health and performance of individuals performing heavy physical training. It is        anticipated that this methodology could also be employed in obesity research to delineate,        longitudinally, the reported cross-sectional relationships among IML stores, insulin        resistance and obesity._Inclusion Criteria:              -  Healthy volunteers (developmental phase)              -  Healthy endurance-trained subjects              -  Maximum age for males is 39              -  Maximum age for females is 49_Obesity',\n",
       " 'D000111': '_Intraoral Grafting of Ex Vivo Produced Oral Mucosal Composites_The purpose of this study is to see if we can develop a good graft for oral mucosal tissue        that is like the top of the mouth in a \"test tube\" that could be used successfully in humans.        We have already done this successfully mice. The next step is to take a small piece of tissue        from a human volunteer and see if we can grow a larger piece of tissue from it outside the        human body and graft it back into the same person successfully. We expect that this technique        will work. It has already been tried in patients with burns of the skin who have had similar        procedures where the skin is grafted back to them. The significance of this research is that        oral tissue taken from the top of the mouth or palate is in limited supply and leaves the        patient with a painful and uncomfortable post surgery experience. If we are successful with        our technique the patient will experience less pain and discomfort from the site that we are        using to grow our tissue outside the body than if we had taken it from the top of the mouth        or palate. In addition, by waiting longer periods to grow the patient\\'s cells we can make        larger pieces of oral tissue than we could have gotten directly from the patient\\'s mouth.        Patients who will participate in this study will need to require a soft tissue graft from the        mouth to an area that needs additional attached or keratinized mucosa. This will most likely        be either in preparation for patients who have or will have dental implants placed. Another        subset of patients are those who need scar tissue released or the vestibule of their mouth        (area that turns from the gums to the lip) released._Inclusion Criteria:              -  Lack sufficient attached keratinized tissue at recipient surgical site in question_Mouth Diseases',\n",
       " 'D000112': '_Prevalence of Carbohydrate Intolerance in Lean and Obese Children_The prevalence of obesity in children is reaching epidemic proportions. Excess adiposity is        more than just a cosmetic problem, having substantial metabolic consequences. Insulin        resistance, hyperinsulinemia, impaired glucose tolerance, and frank diabetes are often seen        in obese children. In this study the prevalence of impaired glucose (carbohydrate) tolerance        in lean children with a family history of diabetes and obese children with acanthosis        nigricans with or without a family history of diabetes mellitus will be studied._Inclusion Criteria:              -  Obesity: BM +/- 95% for age general good health_Obesity',\n",
       " 'D000113': 'Myopia (nearsightedness) is an important public health problem, which entails substantial        societal and personal costs. It is highly prevalent in our society and even more frequent in        Asian countries; furthermore, its prevalence may be increasing over time. High myopia        contributes to significant loss of vision and blindness. At present, the mechanisms involved        in the etiology of myopia are unclear, and there is no way to prevent the condition. Current        methods of correction require lifelong use of lenses or surgical treatment, which is        expensive and may lead to complications. The rationale for this trial, the Correction of        Myopia Evaluation Trial (COMET), arises from the convergence of research involving (1) the        link between accommodation and myopia in children and (2) animal models of myopia showing the        important role of the visual environment in eye growth. A contribution of this research is        that blur is a critical component in the development of myopia. The primary aim of COMET, to        evaluate the efficacy of progressive addition lenses, a noninvasive intervention, in slowing        the progression of myopia, follows from this line of reasoning. These lenses should provide        clear visual input over a range of viewing distances without focusing effort by the child.        The comparison of myopia progression in children treated with PALs versus single vision        lenses will allow the quantification of the effect of PALs on myopia progression during the        followup period.          The COMET is a multicenter, randomized, double-masked clinical trial to evaluate whether PALs        slow the progression of juvenile-onset myopia as compared with single vision lenses. The        study is a collaborative effort that involves a Study Chair at the New England College of        Optometry; four clinical centers at colleges of optometry in Boston, Birmingham,        Philadelphia, and Houston; and a Coordinating Center at the State University of New York at        Stony Brook.          The sample size goal, 450 children with myopia in both eyes who met specific inclusion and        exclusion criteria, was attained with the enrollment of 469 children in one year. Children        were identified from school screenings, clinic records, and referrals from local        practitioners. Eligible children were randomly assigned to receive progressive addition or        single vision lenses. Participating children are being examined at 6-month intervals        following baseline, for at least 3 years, to measure changes in refractive error and to        update prescriptions, according to a specified protocol. A dilated examination to evaluate        the study outcome measures is performed at the annual study visits. A standardized, common        protocol is used at all centers.          The primary outcome of the study is progression of myopia, defined as the magnitude of the        change relative to baseline in spherical equivalent refraction, determined by cycloplegic        autorefraction. The secondary outcome of the study is axial length measured by A-scan        ultrasonography._Correction of Myopia Evaluation Trial (COMET)_To evaluate whether progressive addition lenses (PALs) slow the rate of progression of        juvenile-onset myopia (nearsightedness) when compared with single vision lenses, as measured        by cycloplegic autorefraction. An additional outcome measure is axial length, as measured by        A-scan ultrasonography.          To describe the natural history of juvenile-onset myopia in a group of children receiving        conventional treatment (single vision lenses)._Children between the ages of 6 and 12 years with myopia in both eyes (defined as spherical          equivalent between -1.25 D and -4.50 D in each eye as measured by cycloplegic          autorefraction), astigmatism less than or equal to 1.50 D, and no anisometropia (defined as          a difference in spherical equivalent between the two eyes greater than 1.0 D) are eligible          for inclusion. Exclusion criteria include visual acuity greater than 20/25, strabismus, use          of contact lenses, birth weight less than 1,250 grams, use of bifocal or progressive          addition lenses, or any conditions precluding adherence to the protocol._Myopia'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the dataframe to HashMap/dictionary where the nct_id our document id is the key and the rest columns are values\n",
    "df_clinical_trialdict = df_clinical_trial.set_index('nct_id').apply(lambda x: x['detailed_description']+ '_' + x['brief_title']+ '_' + x['brief_summary']+ '_' + x['eligibility_condition']+ '_' + x['condition'], axis=1).to_dict()\n",
    "df_clinical_trialdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09fedafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the data from the XML file and converting ino DF.\n",
    "def queries_topics():\n",
    "    queries=pd.DataFrame(columns=['Queries'])\n",
    "    url = 'https://www.trec-cds.org/topics2021.xml'\n",
    "\n",
    "    # headers = {'User-Agent': 'Mozilla/5.0' , \"Accept\": \"application/xml\"}\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "    }\n",
    "    req = urllib.request.Request(url, headers=headers)\n",
    "    xml_data = urllib.request.urlopen(req).read()\n",
    "\n",
    "\n",
    "    root = ET.fromstring(xml_data)\n",
    "    for topic in root.iter('topic'):\n",
    "        queries.loc[len(queries.index)] =[topic.text.strip()]\n",
    "    return queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a9f2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient is a 45-year-old man with a history of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48 M with a h/o HTN hyperlipidemia, bicuspid a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 32 yo woman who presents following a severe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a 44 year old female with PMH of PCOS,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74M hx of CAD s/p CABG, EF 60% prior CVA (no r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>The patient is a 34-year-old obese woman who c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>The patient is a 16-year-old girl recently dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>The patient is a 3-day-old female infant with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>The patient is a 53-year-old man complaining o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>The patient is a 55-year-old man who was recen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Queries\n",
       "0   Patient is a 45-year-old man with a history of...\n",
       "1   48 M with a h/o HTN hyperlipidemia, bicuspid a...\n",
       "2   A 32 yo woman who presents following a severe ...\n",
       "3   This is a 44 year old female with PMH of PCOS,...\n",
       "4   74M hx of CAD s/p CABG, EF 60% prior CVA (no r...\n",
       "..                                                ...\n",
       "70  The patient is a 34-year-old obese woman who c...\n",
       "71  The patient is a 16-year-old girl recently dia...\n",
       "72  The patient is a 3-day-old female infant with ...\n",
       "73  The patient is a 53-year-old man complaining o...\n",
       "74  The patient is a 55-year-old man who was recen...\n",
       "\n",
       "[75 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking our Queries\n",
    "queries_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d21f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a random query to do a search engine retrieval.\n",
    "q=queries_topics()['Queries'].loc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41f714ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to remove punctuations, stopwords and stem words\n",
    "def preprocessing_documents():\n",
    "    df_clinical_dict ={}\n",
    "    # loop through the dictionary and process the values\n",
    "    for key, value in df_clinical_trialdict.items():\n",
    "        # Removing numbers, symbols and punctuations\n",
    "        value=re.sub(r'≥|µ|\\d+', '', value).translate(translator).lower().split()\n",
    "        # Remove stopwords from the hashmap D\n",
    "        filtered_words = [word for word in value if word not in stopwords and len(word) > 1]\n",
    "        # Creating a stem of all the words from the document\n",
    "        stemming = snowball.SnowballStemmer('english')\n",
    "        stemming_wwrds = [stemming.stem(x) for x in filtered_words]\n",
    "        df_clinical_dict[key] = list(stemming_wwrds)\n",
    "    #Final pre-processed document\n",
    "    return df_clinical_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15715d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating a second dictionary to store the token and the list of documents it is present and the number of occurences\n",
    "def doc_occurences():\n",
    "    second_dict={}\n",
    "    for key,value in  preprocessing_documents().items():\n",
    "    #     key=int(key)\n",
    "        for i in range(len(value)): # running through each key and its respective value\n",
    "            if value[i] in second_dict:  # checking whether the value is present or not \n",
    "                if key not in second_dict[value[i]].keys(): \n",
    "    # this condition is because when the loop goes to second document id it has to add multiple occurences of a particular word\n",
    "                    second_dict[value[i]][key]=1\n",
    "                else:\n",
    "                    second_dict[value[i]][key]+=1 # else increase the count by 1\n",
    "            else:           \n",
    "                second_dict[value[i]]={key:1} # create a multi level dictionary to add the words , the document id and the ouccrence\n",
    "    return second_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "231b3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the dictionary keyas based on Alphabetic order \n",
    "sorted_dict = {key: value for key, value in sorted(doc_occurences().items())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "380eab98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\tTotal Freq\tDocument Freq\tPosting(Doc-ID, Count)\n",
      "abil           3              2              [('D000102', 2), ('D000105', 1)]\n",
      "acanthosi      1              1              [('D000112', 1)]\n",
      "accommod       1              1              [('D000113', 1)]\n",
      "accord         2              2              [('D000106', 1), ('D000113', 1)]\n",
      "acr            1              1              [('D000106', 1)]\n",
      "acrfor         1              1              [('D000106', 1)]\n",
      "acth           2              1              [('D000102', 2)]\n",
      "activ          4              3              [('D000106', 2), ('D000107', 1), ('D000108', 1)]\n",
      "acuiti         1              1              [('D000113', 1)]\n",
      "acut           2              2              [('D000102', 1), ('D000105', 1)]\n",
      "add            1              1              [('D000108', 1)]\n",
      "addit          7              2              [('D000111', 2), ('D000113', 5)]\n",
      "adequ          3              1              [('D000106', 3)]\n",
      "adher          1              1              [('D000113', 1)]\n",
      "adipos         1              1              [('D000112', 1)]\n",
      "adjuv          2              1              [('D000105', 2)]\n",
      "administ       1              1              [('D000105', 1)]\n",
      "adren          5              1              [('D000102', 5)]\n",
      "adrenocorticotrop1              1              [('D000102', 1)]\n",
      "adult          2              1              [('D000107', 2)]\n",
      "affect         1              1              [('D000104', 1)]\n",
      "age            5              4              [('D000107', 1), ('D000110', 2), ('D000112', 1), ('D000113', 1)]\n",
      "agespecif      1              1              [('D000104', 1)]\n",
      "aim            1              1              [('D000113', 1)]\n",
      "allergi        1              1              [('D000105', 1)]\n",
      "allow          3              3              [('D000106', 1), ('D000108', 1), ('D000113', 1)]\n",
      "along          2              2              [('D000104', 1), ('D000107', 1)]\n",
      "alreadi        2              1              [('D000111', 2)]\n",
      "also           2              2              [('D000105', 1), ('D000110', 1)]\n",
      "alter          1              1              [('D000104', 1)]\n",
      "although       1              1              [('D000105', 1)]\n",
      "american       1              1              [('D000106', 1)]\n",
      "among          1              1              [('D000110', 1)]\n",
      "anecdot        1              1              [('D000106', 1)]\n",
      "anim           1              1              [('D000113', 1)]\n",
      "anisometropia  1              1              [('D000113', 1)]\n",
      "annual         1              1              [('D000113', 1)]\n",
      "anoth          1              1              [('D000111', 1)]\n",
      "antagonist     1              1              [('D000102', 1)]\n",
      "anticip        1              1              [('D000110', 1)]\n",
      "antiinflammatori1              1              [('D000106', 1)]\n",
      "antirheumat    1              1              [('D000106', 1)]\n",
      "appli          1              1              [('D000110', 1)]\n",
      "applic         1              1              [('D000106', 1)]\n",
      "approach       1              1              [('D000104', 1)]\n",
      "approv         1              1              [('D000105', 1)]\n",
      "area           2              1              [('D000111', 2)]\n",
      "aris           1              1              [('D000113', 1)]\n",
      "arm            7              2              [('D000105', 6), ('D000110', 1)]\n",
      "arthriti       2              1              [('D000106', 2)]\n",
      "ascan          2              1              [('D000113', 2)]\n",
      "asian          1              1              [('D000113', 1)]\n",
      "ask            1              1              [('D000105', 1)]\n",
      "assess         3              2              [('D000102', 2), ('D000105', 1)]\n",
      "assign         2              2              [('D000110', 1), ('D000113', 1)]\n",
      "astigmat       1              1              [('D000113', 1)]\n",
      "athlet         1              1              [('D000110', 1)]\n",
      "attach         2              1              [('D000111', 2)]\n",
      "attack         1              1              [('D000108', 1)]\n",
      "attain         1              1              [('D000113', 1)]\n",
      "attent         4              1              [('D000104', 4)]\n",
      "attenu         1              1              [('D000102', 1)]\n",
      "autorefract    3              1              [('D000113', 3)]\n",
      "avail          1              1              [('D000105', 1)]\n",
      "axi            2              1              [('D000102', 2)]\n",
      "axial          2              1              [('D000113', 2)]\n",
      "azathioprin    1              1              [('D000106', 1)]\n",
      "back           2              1              [('D000111', 2)]\n",
      "base           1              1              [('D000104', 1)]\n",
      "baselin        3              2              [('D000102', 1), ('D000113', 2)]\n",
      "basi           2              1              [('D000106', 2)]\n",
      "basic          1              1              [('D000108', 1)]\n",
      "becom          1              1              [('D000105', 1)]\n",
      "begin          1              1              [('D000102', 1)]\n",
      "behavior       1              1              [('D000104', 1)]\n",
      "better         2              1              [('D000105', 2)]\n",
      "beyond         1              1              [('D000106', 1)]\n",
      "bifoc          1              1              [('D000113', 1)]\n",
      "biolog         2              1              [('D000106', 2)]\n",
      "biosyn         2              1              [('D000105', 2)]\n",
      "birmingham     1              1              [('D000113', 1)]\n",
      "birth          1              1              [('D000113', 1)]\n",
      "blind          1              1              [('D000113', 1)]\n",
      "blood          7              5              [('D000102', 1), ('D000105', 3), ('D000106', 1), ('D000107', 1), ('D000108', 1)]\n",
      "blur           1              1              [('D000113', 1)]\n",
      "bm             1              1              [('D000112', 1)]\n",
      "bmi            1              1              [('D000108', 1)]\n",
      "bodi           16             5              [('D000105', 4), ('D000106', 2), ('D000107', 5), ('D000108', 3), ('D000111', 2)]\n",
      "bone           1              1              [('D000106', 1)]\n",
      "boost          2              1              [('D000105', 2)]\n",
      "boston         1              1              [('D000113', 1)]\n",
      "bout           1              1              [('D000110', 1)]\n",
      "breath         1              1              [('D000107', 1)]\n",
      "brook          1              1              [('D000113', 1)]\n",
      "burden         1              1              [('D000104', 1)]\n",
      "burn           1              1              [('D000111', 1)]\n",
      "cah            1              1              [('D000102', 1)]\n",
      "cahcongenit    1              1              [('D000102', 1)]\n",
      "cahinclus      1              1              [('D000102', 1)]\n",
      "calcium        3              2              [('D000102', 2), ('D000106', 1)]\n",
      "call           1              1              [('D000105', 1)]\n",
      "calori         1              1              [('D000107', 1)]\n",
      "cancer         7              1              [('D000105', 7)]\n",
      "candid         1              1              [('D000106', 1)]\n",
      "carbohydr      2              1              [('D000112', 2)]\n",
      "cardiac        1              1              [('D000106', 1)]\n",
      "cardiovascular 2              2              [('D000102', 1), ('D000108', 1)]\n",
      "carri          1              1              [('D000105', 1)]\n",
      "caus           1              1              [('D000108', 1)]\n",
      "cell           6              2              [('D000105', 5), ('D000111', 1)]\n",
      "cellular       1              1              [('D000106', 1)]\n",
      "center         3              1              [('D000113', 3)]\n",
      "centigrad      1              1              [('D000106', 1)]\n",
      "certain        1              1              [('D000106', 1)]\n",
      "chair          1              1              [('D000113', 1)]\n",
      "chanc          1              1              [('D000108', 1)]\n",
      "chang          7              5              [('D000105', 1), ('D000106', 1), ('D000108', 1), ('D000110', 2), ('D000113', 2)]\n",
      "channel        2              1              [('D000102', 2)]\n",
      "character      1              1              [('D000107', 1)]\n",
      "chd            1              1              [('D000108', 1)]\n",
      "chemotherapi   1              1              [('D000105', 1)]\n",
      "child          1              1              [('D000113', 1)]\n",
      "childbear      1              1              [('D000105', 1)]\n",
      "children       17             4              [('D000102', 1), ('D000104', 4), ('D000112', 4), ('D000113', 8)]\n",
      "childrenth     1              1              [('D000112', 1)]\n",
      "chronic        2              2              [('D000102', 1), ('D000107', 1)]\n",
      "circumst       1              1              [('D000105', 1)]\n",
      "citi           1              1              [('D000104', 1)]\n",
      "class          1              1              [('D000106', 1)]\n",
      "clear          1              1              [('D000113', 1)]\n",
      "clinic         6              3              [('D000104', 1), ('D000106', 2), ('D000113', 3)]\n",
      "close          2              1              [('D000105', 2)]\n",
      "clot           1              1              [('D000108', 1)]\n",
      "cognit         1              1              [('D000104', 1)]\n",
      "collabor       1              1              [('D000113', 1)]\n",
      "colleg         3              2              [('D000106', 1), ('D000113', 2)]\n",
      "comet          3              1              [('D000113', 3)]\n",
      "cometto        1              1              [('D000113', 1)]\n",
      "committe       1              1              [('D000105', 1)]\n",
      "common         1              1              [('D000113', 1)]\n",
      "compar         5              3              [('D000105', 2), ('D000110', 1), ('D000113', 2)]\n",
      "comparison     1              1              [('D000113', 1)]\n",
      "complet        1              1              [('D000104', 1)]\n",
      "complic        1              1              [('D000113', 1)]\n",
      "compon         3              2              [('D000105', 2), ('D000113', 1)]\n",
      "compos         1              1              [('D000102', 1)]\n",
      "composit       1              1              [('D000107', 1)]\n",
      "compositesth   1              1              [('D000111', 1)]\n",
      "comput         1              1              [('D000104', 1)]\n",
      "concept        1              1              [('D000106', 1)]\n",
      "condit         2              1              [('D000113', 2)]\n",
      "confirm        1              1              [('D000106', 1)]\n",
      "congenit       8              2              [('D000102', 3), ('D000107', 5)]\n",
      "consent        1              1              [('D000105', 1)]\n",
      "consequ        1              1              [('D000112', 1)]\n",
      "consist        2              2              [('D000105', 1), ('D000107', 1)]\n",
      "consum         1              1              [('D000110', 1)]\n",
      "contact        1              1              [('D000113', 1)]\n",
      "content        1              1              [('D000107', 1)]\n",
      "contribut      2              1              [('D000113', 2)]\n",
      "control        3              2              [('D000105', 2), ('D000107', 1)]\n",
      "convent        1              1              [('D000113', 1)]\n",
      "converg        1              1              [('D000113', 1)]\n",
      "coordin        1              1              [('D000113', 1)]\n",
      "correct        2              1              [('D000113', 2)]\n",
      "corticosteroid 1              1              [('D000106', 1)]\n",
      "cosmet         1              1              [('D000112', 1)]\n",
      "cost           1              1              [('D000113', 1)]\n",
      "could          3              2              [('D000110', 1), ('D000111', 2)]\n",
      "countri        1              1              [('D000113', 1)]\n",
      "cours          2              2              [('D000105', 1), ('D000110', 1)]\n",
      "crc            2              1              [('D000104', 2)]\n",
      "creactiv       1              1              [('D000106', 1)]\n",
      "criteria       18             10             [('D000102', 2), ('D000104', 1), ('D000105', 2), ('D000106', 6), ('D000107', 1), ('D000108', 1), ('D000110', 1), ('D000111', 1), ('D000112', 1), ('D000113', 2)]\n",
      "critic         1              1              [('D000113', 1)]\n",
      "crossov        1              1              [('D000110', 1)]\n",
      "crosssect      1              1              [('D000110', 1)]\n",
      "current        1              1              [('D000113', 1)]\n",
      "cvd            2              1              [('D000108', 2)]\n",
      "cvdinclus      1              1              [('D000108', 1)]\n",
      "cyanot         4              1              [('D000107', 4)]\n",
      "cyclopleg      3              1              [('D000113', 3)]\n",
      "cytokin        1              1              [('D000106', 1)]\n",
      "day            2              2              [('D000106', 1), ('D000108', 1)]\n",
      "death          1              1              [('D000108', 1)]\n",
      "decilit        1              1              [('D000106', 1)]\n",
      "decreas        4              1              [('D000102', 4)]\n",
      "defect         2              1              [('D000107', 2)]\n",
      "defin          3              1              [('D000113', 3)]\n",
      "degre          2              1              [('D000106', 2)]\n",
      "dehydr         1              1              [('D000107', 1)]\n",
      "deleteri       1              1              [('D000102', 1)]\n",
      "delin          2              2              [('D000104', 1), ('D000110', 1)]\n",
      "dental         1              1              [('D000111', 1)]\n",
      "deplet         1              1              [('D000110', 1)]\n",
      "deriv          1              1              [('D000105', 1)]\n",
      "describ        1              1              [('D000113', 1)]\n",
      "design         2              1              [('D000102', 2)]\n",
      "detect         2              1              [('D000105', 2)]\n",
      "determin       2              2              [('D000110', 1), ('D000113', 1)]\n",
      "develop        7              5              [('D000104', 1), ('D000105', 1), ('D000108', 3), ('D000111', 1), ('D000113', 1)]\n",
      "development    1              1              [('D000110', 1)]\n",
      "developmentinn 1              1              [('D000104', 1)]\n",
      "diabet         3              1              [('D000112', 3)]\n",
      "diagnos        1              1              [('D000102', 1)]\n",
      "diagnosi       1              1              [('D000105', 1)]\n",
      "diet           7              1              [('D000110', 7)]\n",
      "dietari        1              1              [('D000110', 1)]\n",
      "differ         5              4              [('D000104', 1), ('D000105', 1), ('D000108', 2), ('D000113', 1)]\n",
      "dilat          1              1              [('D000113', 1)]\n",
      "dip            1              1              [('D000108', 1)]\n",
      "direct         1              1              [('D000111', 1)]\n",
      "discomfort     1              1              [('D000111', 1)]\n",
      "diseas         10             5              [('D000102', 1), ('D000106', 4), ('D000107', 2), ('D000108', 2), ('D000111', 1)]\n",
      "diseaseadult   1              1              [('D000107', 1)]\n",
      "diseasecongenit1              1              [('D000102', 1)]\n",
      "diseasemodifi  1              1              [('D000106', 1)]\n",
      "diseasesrec    1              1              [('D000106', 1)]\n",
      "distanc        1              1              [('D000113', 1)]\n",
      "dobutamin      1              1              [('D000106', 1)]\n",
      "document       1              1              [('D000110', 1)]\n",
      "done           1              1              [('D000111', 1)]\n",
      "dosag          2              2              [('D000102', 1), ('D000106', 1)]\n",
      "dose           1              1              [('D000102', 1)]\n",
      "dosedepend     1              1              [('D000102', 1)]\n",
      "doubleblind    1              1              [('D000102', 1)]\n",
      "doublemask     1              1              [('D000113', 1)]\n",
      "drug           4              2              [('D000105', 2), ('D000106', 2)]\n",
      "ecg            1              1              [('D000102', 1)]\n",
      "echo           2              1              [('D000106', 2)]\n",
      "effect         14             6              [('D000102', 4), ('D000104', 5), ('D000105', 1), ('D000108', 2), ('D000110', 1), ('D000113', 1)]\n",
      "efficaci       2              2              [('D000106', 1), ('D000113', 1)]\n",
      "effort         2              1              [('D000113', 2)]\n",
      "eight          1              1              [('D000104', 1)]\n",
      "either         1              1              [('D000111', 1)]\n",
      "electrod       1              1              [('D000104', 1)]\n",
      "electrolyt     1              1              [('D000106', 1)]\n",
      "electrophysiolog1              1              [('D000104', 1)]\n",
      "elev           2              2              [('D000102', 1), ('D000107', 1)]\n",
      "elig           6              3              [('D000105', 2), ('D000106', 2), ('D000113', 2)]\n",
      "eligiblerheumat1              1              [('D000106', 1)]\n",
      "employ         1              1              [('D000110', 1)]\n",
      "endpoint       1              1              [('D000106', 1)]\n",
      "endur          4              1              [('D000110', 4)]\n",
      "endurancetrain 1              1              [('D000110', 1)]\n",
      "energi         2              1              [('D000110', 2)]\n",
      "england        1              1              [('D000113', 1)]\n",
      "enrol          2              2              [('D000106', 1), ('D000113', 1)]\n",
      "entail         1              1              [('D000113', 1)]\n",
      "entri          1              1              [('D000106', 1)]\n",
      "environ        1              1              [('D000113', 1)]\n",
      "epidem         1              1              [('D000112', 1)]\n",
      "equal          2              2              [('D000105', 1), ('D000113', 1)]\n",
      "equival        3              1              [('D000113', 3)]\n",
      "erp            3              1              [('D000104', 3)]\n",
      "error          1              1              [('D000113', 1)]\n",
      "erythrocyt     1              1              [('D000106', 1)]\n",
      "especi         1              1              [('D000105', 1)]\n",
      "etiolog        1              1              [('D000113', 1)]\n",
      "evalu          9              3              [('D000102', 2), ('D000110', 1), ('D000113', 6)]\n",
      "even           1              1              [('D000113', 1)]\n",
      "eventrel       1              1              [('D000104', 1)]\n",
      "everi          1              1              [('D000104', 1)]\n",
      "ex             1              1              [('D000111', 1)]\n",
      "examin         3              2              [('D000102', 1), ('D000113', 2)]\n",
      "exampl         1              1              [('D000105', 1)]\n",
      "excess         1              1              [('D000112', 1)]\n",
      "exclud         1              1              [('D000105', 1)]\n",
      "exclus         4              3              [('D000102', 1), ('D000105', 1), ('D000113', 2)]\n",
      "exercis        7              3              [('D000106', 2), ('D000108', 4), ('D000110', 1)]\n",
      "expect         2              2              [('D000105', 1), ('D000111', 1)]\n",
      "expens         1              1              [('D000113', 1)]\n",
      "experi         3              2              [('D000106', 1), ('D000111', 2)]\n",
      "extend         1              1              [('D000102', 1)]\n",
      "extent         1              1              [('D000108', 1)]\n",
      "extramur       1              1              [('D000110', 1)]\n",
      "extrem         2              1              [('D000110', 2)]\n",
      "eye            5              1              [('D000113', 5)]\n",
      "factor         4              1              [('D000108', 4)]\n",
      "factorreceptor 1              1              [('D000106', 1)]\n",
      "famili         2              1              [('D000112', 2)]\n",
      "fashion        1              1              [('D000110', 1)]\n",
      "fat            6              3              [('D000107', 1), ('D000108', 2), ('D000110', 3)]\n",
      "fatfre         1              1              [('D000107', 1)]\n",
      "febril         1              1              [('D000105', 1)]\n",
      "femal          2              2              [('D000105', 1), ('D000110', 1)]\n",
      "fev            1              1              [('D000106', 1)]\n",
      "fibrinogen     1              1              [('D000108', 1)]\n",
      "fight          1              1              [('D000105', 1)]\n",
      "find           2              2              [('D000106', 1), ('D000108', 1)]\n",
      "flare          1              1              [('D000106', 1)]\n",
      "focus          1              1              [('D000113', 1)]\n",
      "follow         6              3              [('D000106', 2), ('D000110', 2), ('D000113', 2)]\n",
      "followup       3              3              [('D000105', 1), ('D000106', 1), ('D000113', 1)]\n",
      "forc           1              1              [('D000110', 1)]\n",
      "foreign        2              1              [('D000105', 2)]\n",
      "form           1              1              [('D000108', 1)]\n",
      "four           3              3              [('D000105', 1), ('D000106', 1), ('D000113', 1)]\n",
      "frank          1              1              [('D000112', 1)]\n",
      "frequent       1              1              [('D000113', 1)]\n",
      "fulfil         1              1              [('D000106', 1)]\n",
      "function       7              3              [('D000102', 1), ('D000104', 2), ('D000106', 4)]\n",
      "furthermor     1              1              [('D000113', 1)]\n",
      "gase           1              1              [('D000106', 1)]\n",
      "gender         1              1              [('D000107', 1)]\n",
      "general        2              2              [('D000108', 1), ('D000112', 1)]\n",
      "get            3              1              [('D000105', 3)]\n",
      "give           2              1              [('D000105', 2)]\n",
      "given          2              1              [('D000105', 2)]\n",
      "glucocorticoid 3              1              [('D000102', 3)]\n",
      "glucos         2              1              [('D000112', 2)]\n",
      "go             1              1              [('D000104', 1)]\n",
      "goal           4              3              [('D000102', 2), ('D000105', 1), ('D000113', 1)]\n",
      "gold           1              1              [('D000106', 1)]\n",
      "good           4              4              [('D000105', 1), ('D000108', 1), ('D000111', 1), ('D000112', 1)]\n",
      "gotten         1              1              [('D000111', 1)]\n",
      "graft          5              1              [('D000111', 5)]\n",
      "gram           1              1              [('D000113', 1)]\n",
      "grant          1              1              [('D000110', 1)]\n",
      "great          1              1              [('D000105', 1)]\n",
      "greater        2              1              [('D000113', 2)]\n",
      "group          1              1              [('D000113', 1)]\n",
      "grow           3              1              [('D000111', 3)]\n",
      "growth         1              1              [('D000113', 1)]\n",
      "gum            1              1              [('D000111', 1)]\n",
      "health         4              4              [('D000105', 1), ('D000108', 1), ('D000110', 1), ('D000113', 1)]\n",
      "healthi        7              3              [('D000105', 4), ('D000107', 1), ('D000110', 2)]\n",
      "healthobes     1              1              [('D000112', 1)]\n",
      "heart          8              3              [('D000106', 1), ('D000107', 5), ('D000108', 2)]\n",
      "heat           1              1              [('D000106', 1)]\n",
      "heavi          1              1              [('D000110', 1)]\n",
      "high           3              2              [('D000108', 1), ('D000113', 2)]\n",
      "histolog       1              1              [('D000105', 1)]\n",
      "histori        6              4              [('D000102', 2), ('D000105', 1), ('D000112', 2), ('D000113', 1)]\n",
      "hormon         2              2              [('D000102', 1), ('D000108', 1)]\n",
      "hour           2              2              [('D000106', 1), ('D000110', 1)]\n",
      "houston        1              1              [('D000113', 1)]\n",
      "howev          1              1              [('D000104', 1)]\n",
      "hpa            1              1              [('D000102', 1)]\n",
      "human          4              2              [('D000105', 1), ('D000111', 3)]\n",
      "hydroxychloroquinin1              1              [('D000106', 1)]\n",
      "hyperinsulinemia1              1              [('D000112', 1)]\n",
      "hyperplasia    5              1              [('D000102', 5)]\n",
      "hypersensit    1              1              [('D000105', 1)]\n",
      "hyperthermia   2              1              [('D000106', 2)]\n",
      "hypothalamicpituitaryadren1              1              [('D000102', 1)]\n",
      "hypothes       1              1              [('D000110', 1)]\n",
      "hypothesi      1              1              [('D000106', 1)]\n",
      "identifi       1              1              [('D000113', 1)]\n",
      "ii             3              2              [('D000102', 1), ('D000106', 2)]\n",
      "iii            1              1              [('D000106', 1)]\n",
      "il             1              1              [('D000105', 1)]\n",
      "ill            2              1              [('D000105', 2)]\n",
      "imag           1              1              [('D000104', 1)]\n",
      "iml            7              1              [('D000110', 7)]\n",
      "immun          14             1              [('D000105', 14)]\n",
      "impair         3              2              [('D000110', 1), ('D000112', 2)]\n",
      "implant        1              1              [('D000111', 1)]\n",
      "import         3              2              [('D000104', 1), ('D000113', 2)]\n",
      "improv         1              1              [('D000105', 1)]\n",
      "includ         4              4              [('D000104', 1), ('D000105', 1), ('D000106', 1), ('D000113', 1)]\n",
      "inclus         2              1              [('D000113', 2)]\n",
      "increas        5              4              [('D000104', 1), ('D000105', 1), ('D000108', 2), ('D000113', 1)]\n",
      "index          2              2              [('D000104', 1), ('D000108', 1)]\n",
      "individu       1              1              [('D000110', 1)]\n",
      "induc          2              1              [('D000106', 2)]\n",
      "induct         1              1              [('D000106', 1)]\n",
      "inelig         1              1              [('D000105', 1)]\n",
      "infect         4              1              [('D000105', 4)]\n",
      "influenc       1              1              [('D000110', 1)]\n",
      "inform         2              2              [('D000104', 1), ('D000105', 1)]\n",
      "inher          1              1              [('D000106', 1)]\n",
      "inhibitor      1              1              [('D000108', 1)]\n",
      "inject         1              1              [('D000106', 1)]\n",
      "input          1              1              [('D000113', 1)]\n",
      "insulin        2              2              [('D000110', 1), ('D000112', 1)]\n",
      "intens         4              1              [('D000108', 4)]\n",
      "intercurr      1              1              [('D000105', 1)]\n",
      "interest       1              1              [('D000105', 1)]\n",
      "interfer       1              1              [('D000105', 1)]\n",
      "interleukin    1              1              [('D000105', 1)]\n",
      "interv         1              1              [('D000113', 1)]\n",
      "intervent      2              2              [('D000105', 1), ('D000113', 1)]\n",
      "intoler        1              1              [('D000112', 1)]\n",
      "intracel       1              1              [('D000105', 1)]\n",
      "intramuscular  5              2              [('D000105', 3), ('D000110', 2)]\n",
      "intraor        1              1              [('D000111', 1)]\n",
      "investig       3              2              [('D000106', 1), ('D000110', 2)]\n",
      "involv         4              2              [('D000102', 1), ('D000113', 3)]\n",
      "isa            1              1              [('D000105', 1)]\n",
      "issu           1              1              [('D000108', 1)]\n",
      "joint          2              1              [('D000106', 2)]\n",
      "juvenileonset  3              1              [('D000113', 3)]\n",
      "karnofski      1              1              [('D000105', 1)]\n",
      "keratin        2              1              [('D000111', 2)]\n",
      "kgheight       1              1              [('D000108', 1)]\n",
      "kill           1              1              [('D000105', 1)]\n",
      "klh            7              1              [('D000105', 7)]\n",
      "know           2              1              [('D000105', 2)]\n",
      "lack           2              2              [('D000106', 1), ('D000111', 1)]\n",
      "lactat         1              1              [('D000105', 1)]\n",
      "larger         5              2              [('D000104', 3), ('D000111', 2)]\n",
      "last           1              1              [('D000105', 1)]\n",
      "ldlcholesterol 1              1              [('D000108', 1)]\n",
      "lead           10             4              [('D000104', 7), ('D000107', 1), ('D000108', 1), ('D000113', 1)]\n",
      "lean           3              2              [('D000107', 1), ('D000112', 2)]\n",
      "learn          2              1              [('D000105', 2)]\n",
      "least          6              3              [('D000105', 1), ('D000106', 4), ('D000113', 1)]\n",
      "leav           1              1              [('D000111', 1)]\n",
      "length         2              1              [('D000113', 2)]\n",
      "lens           10             1              [('D000113', 10)]\n",
      "lenseschildren 1              1              [('D000113', 1)]\n",
      "less           4              3              [('D000108', 1), ('D000111', 1), ('D000113', 2)]\n",
      "level          9              4              [('D000102', 1), ('D000106', 4), ('D000107', 1), ('D000108', 3)]\n",
      "lifelong       1              1              [('D000113', 1)]\n",
      "like           5              3              [('D000105', 2), ('D000107', 1), ('D000111', 2)]\n",
      "limit          1              1              [('D000111', 1)]\n",
      "line           1              1              [('D000113', 1)]\n",
      "link           1              1              [('D000113', 1)]\n",
      "lip            1              1              [('D000111', 1)]\n",
      "lipid          2              1              [('D000110', 2)]\n",
      "liver          3              2              [('D000102', 2), ('D000106', 1)]\n",
      "local          2              2              [('D000104', 1), ('D000113', 1)]\n",
      "longer         1              1              [('D000111', 1)]\n",
      "longitudin     1              1              [('D000110', 1)]\n",
      "longterm       1              1              [('D000102', 1)]\n",
      "lose           1              1              [('D000108', 1)]\n",
      "loss           1              1              [('D000113', 1)]\n",
      "lowfat         3              1              [('D000110', 3)]\n",
      "magnet         1              1              [('D000110', 1)]\n",
      "magnitud       1              1              [('D000113', 1)]\n",
      "make           1              1              [('D000111', 1)]\n",
      "male           1              1              [('D000110', 1)]\n",
      "mani           1              1              [('D000105', 1)]\n",
      "marrow         1              1              [('D000106', 1)]\n",
      "mass           2              2              [('D000107', 1), ('D000108', 1)]\n",
      "match          2              2              [('D000104', 1), ('D000107', 1)]\n",
      "maximum        3              2              [('D000106', 1), ('D000110', 2)]\n",
      "may            4              3              [('D000105', 1), ('D000106', 1), ('D000113', 2)]\n",
      "mcg            3              1              [('D000105', 3)]\n",
      "measur         16             6              [('D000104', 3), ('D000105', 2), ('D000107', 2), ('D000108', 1), ('D000110', 1), ('D000113', 7)]\n",
      "measuresinclus 1              1              [('D000104', 1)]\n",
      "mechan         1              1              [('D000113', 1)]\n",
      "medic          3              2              [('D000102', 2), ('D000105', 1)]\n",
      "meet           1              1              [('D000106', 1)]\n",
      "mellitus       1              1              [('D000112', 1)]\n",
      "memori         4              1              [('D000104', 4)]\n",
      "mercuri        1              1              [('D000105', 1)]\n",
      "met            1              1              [('D000113', 1)]\n",
      "metabol        2              2              [('D000107', 1), ('D000112', 1)]\n",
      "method         1              1              [('D000113', 1)]\n",
      "methodolog     1              1              [('D000110', 1)]\n",
      "methotrex      1              1              [('D000106', 1)]\n",
      "mg             5              2              [('D000105', 3), ('D000106', 2)]\n",
      "mgdl           1              1              [('D000108', 1)]\n",
      "mice           1              1              [('D000111', 1)]\n",
      "might          1              1              [('D000106', 1)]\n",
      "minday         1              1              [('D000108', 1)]\n",
      "minneapoli     1              1              [('D000104', 1)]\n",
      "minnesota      2              2              [('D000104', 1), ('D000105', 1)]\n",
      "minut          2              1              [('D000106', 2)]\n",
      "ml             3              1              [('D000105', 3)]\n",
      "mm             1              1              [('D000106', 1)]\n",
      "model          1              1              [('D000113', 1)]\n",
      "moderatefat    3              1              [('D000110', 3)]\n",
      "monitor        1              1              [('D000105', 1)]\n",
      "mono           2              1              [('D000105', 2)]\n",
      "mononucleosi   1              1              [('D000105', 1)]\n",
      "montanid       1              1              [('D000105', 1)]\n",
      "month          4              3              [('D000104', 1), ('D000105', 2), ('D000113', 1)]\n",
      "morn           1              1              [('D000106', 1)]\n",
      "mother         1              1              [('D000104', 1)]\n",
      "mouth          6              1              [('D000111', 6)]\n",
      "mrs            1              1              [('D000110', 1)]\n",
      "much           1              1              [('D000107', 1)]\n",
      "mucos          2              1              [('D000111', 2)]\n",
      "mucosa         1              1              [('D000111', 1)]\n",
      "muga           1              1              [('D000106', 1)]\n",
      "multicent      2              2              [('D000102', 1), ('D000113', 1)]\n",
      "multimodel     1              1              [('D000104', 1)]\n",
      "must           8              2              [('D000105', 4), ('D000106', 4)]\n",
      "mvv            1              1              [('D000106', 1)]\n",
      "myopia         17             1              [('D000113', 17)]\n",
      "narcot         1              1              [('D000106', 1)]\n",
      "nation         1              1              [('D000105', 1)]\n",
      "natruret       1              1              [('D000107', 1)]\n",
      "natur          1              1              [('D000113', 1)]\n",
      "nearsighted    2              1              [('D000113', 2)]\n",
      "necessari      1              1              [('D000106', 1)]\n",
      "necrosi        1              1              [('D000106', 1)]\n",
      "need           4              2              [('D000102', 1), ('D000111', 3)]\n",
      "neighborhood   1              1              [('D000104', 1)]\n",
      "neurolog       1              1              [('D000105', 1)]\n",
      "neuropsycholog 2              1              [('D000104', 2)]\n",
      "new            2              1              [('D000113', 2)]\n",
      "next           1              1              [('D000111', 1)]\n",
      "nifedipin      6              1              [('D000102', 6)]\n",
      "nigrican       1              1              [('D000112', 1)]\n",
      "nih            1              1              [('D000110', 1)]\n",
      "noncyanot      1              1              [('D000107', 1)]\n",
      "noninvas       1              1              [('D000113', 1)]\n",
      "nonsteroid     1              1              [('D000106', 1)]\n",
      "nontox         1              1              [('D000106', 1)]\n",
      "normal         5              2              [('D000102', 1), ('D000105', 4)]\n",
      "nsaid          1              1              [('D000106', 1)]\n",
      "number         1              1              [('D000107', 1)]\n",
      "obes           7              2              [('D000110', 2), ('D000112', 5)]\n",
      "obesityinclus  1              1              [('D000110', 1)]\n",
      "observ         1              1              [('D000106', 1)]\n",
      "occurr         1              1              [('D000105', 1)]\n",
      "offspringlead  1              1              [('D000104', 1)]\n",
      "often          1              1              [('D000112', 1)]\n",
      "older          1              1              [('D000108', 1)]\n",
      "one            2              2              [('D000106', 1), ('D000113', 1)]\n",
      "open           1              1              [('D000105', 1)]\n",
      "optim          1              1              [('D000108', 1)]\n",
      "optometri      2              1              [('D000113', 2)]\n",
      "oral           5              2              [('D000106', 1), ('D000111', 4)]\n",
      "order          1              1              [('D000105', 1)]\n",
      "organ          1              1              [('D000106', 1)]\n",
      "outcom         4              1              [('D000113', 4)]\n",
      "outsid         2              1              [('D000111', 2)]\n",
      "overal         1              1              [('D000105', 1)]\n",
      "overburden     6              1              [('D000104', 6)]\n",
      "oxygen         2              2              [('D000106', 1), ('D000107', 1)]\n",
      "pain           3              2              [('D000106', 1), ('D000111', 2)]\n",
      "pal            4              1              [('D000113', 4)]\n",
      "palat          2              1              [('D000111', 2)]\n",
      "parallel       1              1              [('D000102', 1)]\n",
      "part           1              1              [('D000104', 1)]\n",
      "particip       3              3              [('D000104', 1), ('D000111', 1), ('D000113', 1)]\n",
      "past           1              1              [('D000105', 1)]\n",
      "patient        29             4              [('D000102', 1), ('D000105', 12), ('D000106', 8), ('D000111', 8)]\n",
      "pattern        1              1              [('D000110', 1)]\n",
      "penicillamin   1              1              [('D000106', 1)]\n",
      "peopl          2              1              [('D000105', 2)]\n",
      "peptid         1              1              [('D000107', 1)]\n",
      "per            3              1              [('D000106', 3)]\n",
      "perform        4              3              [('D000105', 1), ('D000110', 2), ('D000113', 1)]\n",
      "period         3              3              [('D000106', 1), ('D000111', 1), ('D000113', 1)]\n",
      "permit         2              1              [('D000102', 2)]\n",
      "person         2              2              [('D000111', 1), ('D000113', 1)]\n",
      "phase          4              2              [('D000102', 3), ('D000110', 1)]\n",
      "philadelphia   1              1              [('D000113', 1)]\n",
      "phillip        1              1              [('D000104', 1)]\n",
      "physic         1              1              [('D000110', 1)]\n",
      "physiolog      1              1              [('D000104', 1)]\n",
      "piec           3              1              [('D000111', 3)]\n",
      "pilot          2              1              [('D000110', 2)]\n",
      "place          2              2              [('D000104', 1), ('D000111', 1)]\n",
      "placebo        1              1              [('D000102', 1)]\n",
      "placebocontrol 1              1              [('D000102', 1)]\n",
      "plasma         1              1              [('D000107', 1)]\n",
      "plasminogen    1              1              [('D000108', 1)]\n",
      "po             1              1              [('D000106', 1)]\n",
      "poison         1              1              [('D000104', 1)]\n",
      "portion        1              1              [('D000104', 1)]\n",
      "posit          1              1              [('D000106', 1)]\n",
      "post           1              1              [('D000111', 1)]\n",
      "postexercis    1              1              [('D000110', 1)]\n",
      "postmenopaus   3              1              [('D000108', 3)]\n",
      "potenti        2              2              [('D000104', 1), ('D000105', 1)]\n",
      "practition     1              1              [('D000113', 1)]\n",
      "preclud        1              1              [('D000113', 1)]\n",
      "predict        3              2              [('D000106', 2), ('D000108', 1)]\n",
      "prefer         1              1              [('D000108', 1)]\n",
      "pregnanc       1              1              [('D000105', 1)]\n",
      "pregnant       3              2              [('D000104', 2), ('D000105', 1)]\n",
      "prepar         1              1              [('D000111', 1)]\n",
      "prescript      1              1              [('D000113', 1)]\n",
      "present        2              2              [('D000108', 1), ('D000113', 1)]\n",
      "pressur        3              3              [('D000102', 1), ('D000107', 1), ('D000108', 1)]\n",
      "preval         5              2              [('D000112', 3), ('D000113', 2)]\n",
      "prevent        3              2              [('D000105', 2), ('D000113', 1)]\n",
      "primari        2              1              [('D000113', 2)]\n",
      "prior          1              1              [('D000106', 1)]\n",
      "proanp         1              1              [('D000107', 1)]\n",
      "proatrial      1              1              [('D000107', 1)]\n",
      "problem        2              2              [('D000112', 1), ('D000113', 1)]\n",
      "procardia      1              1              [('D000102', 1)]\n",
      "procedur       1              1              [('D000111', 1)]\n",
      "produc         1              1              [('D000111', 1)]\n",
      "product        1              1              [('D000105', 1)]\n",
      "program        1              1              [('D000105', 1)]\n",
      "progress       10             1              [('D000113', 10)]\n",
      "prolong        2              1              [('D000110', 2)]\n",
      "proport        1              1              [('D000112', 1)]\n",
      "protect        1              1              [('D000105', 1)]\n",
      "protein        2              2              [('D000106', 1), ('D000108', 1)]\n",
      "protocol       5              4              [('D000102', 1), ('D000105', 1), ('D000106', 1), ('D000113', 2)]\n",
      "protocolcanc   1              1              [('D000105', 1)]\n",
      "protocolmyopia 1              1              [('D000113', 1)]\n",
      "provid         4              3              [('D000104', 2), ('D000106', 1), ('D000113', 1)]\n",
      "public         1              1              [('D000113', 1)]\n",
      "purpos         5              5              [('D000105', 1), ('D000107', 1), ('D000108', 1), ('D000110', 1), ('D000111', 1)]\n",
      "quantif        1              1              [('D000113', 1)]\n",
      "questionmouth  1              1              [('D000111', 1)]\n",
      "random         3              2              [('D000110', 1), ('D000113', 2)]\n",
      "rang           1              1              [('D000113', 1)]\n",
      "rate           4              4              [('D000106', 1), ('D000107', 1), ('D000108', 1), ('D000113', 1)]\n",
      "rational       1              1              [('D000113', 1)]\n",
      "reach          1              1              [('D000112', 1)]\n",
      "reason         1              1              [('D000113', 1)]\n",
      "receiv         7              3              [('D000105', 4), ('D000106', 1), ('D000113', 2)]\n",
      "receptor       1              1              [('D000106', 1)]\n",
      "receptorsinclus1              1              [('D000106', 1)]\n",
      "recipi         1              1              [('D000111', 1)]\n",
      "recommend      1              1              [('D000108', 1)]\n",
      "record         2              2              [('D000104', 1), ('D000113', 1)]\n",
      "recoveri       1              1              [('D000110', 1)]\n",
      "recruit        3              2              [('D000104', 2), ('D000107', 1)]\n",
      "recurr         1              1              [('D000105', 1)]\n",
      "reduc          5              3              [('D000102', 1), ('D000107', 1), ('D000108', 3)]\n",
      "referr         1              1              [('D000113', 1)]\n",
      "refract        2              1              [('D000113', 2)]\n",
      "relaps         1              1              [('D000105', 1)]\n",
      "relat          1              1              [('D000113', 1)]\n",
      "relationship   1              1              [('D000110', 1)]\n",
      "releas         3              2              [('D000102', 2), ('D000111', 1)]\n",
      "releasedinclus 1              1              [('D000111', 1)]\n",
      "remain         1              1              [('D000106', 1)]\n",
      "rememb         1              1              [('D000105', 1)]\n",
      "remiss         1              1              [('D000106', 1)]\n",
      "renal          1              1              [('D000106', 1)]\n",
      "replac         2              2              [('D000105', 1), ('D000108', 1)]\n",
      "replenish      2              1              [('D000110', 2)]\n",
      "report         1              1              [('D000110', 1)]\n",
      "requir         4              4              [('D000104', 1), ('D000106', 1), ('D000111', 1), ('D000113', 1)]\n",
      "research       5              4              [('D000108', 1), ('D000110', 1), ('D000111', 1), ('D000113', 2)]\n",
      "resist         2              2              [('D000110', 1), ('D000112', 1)]\n",
      "reson          1              1              [('D000110', 1)]\n",
      "respect        1              1              [('D000107', 1)]\n",
      "respiratori    1              1              [('D000106', 1)]\n",
      "respond        2              1              [('D000105', 2)]\n",
      "respons        5              3              [('D000105', 3), ('D000106', 1), ('D000110', 1)]\n",
      "responsesth    1              1              [('D000105', 1)]\n",
      "rest           3              1              [('D000107', 3)]\n",
      "result         2              2              [('D000107', 1), ('D000110', 1)]\n",
      "rheumatoid     4              1              [('D000106', 4)]\n",
      "rheumatolog    1              1              [('D000106', 1)]\n",
      "risk           6              2              [('D000104', 1), ('D000108', 5)]\n",
      "role           1              1              [('D000113', 1)]\n",
      "rule           1              1              [('D000106', 1)]\n",
      "run            3              1              [('D000110', 3)]\n",
      "safe           1              1              [('D000105', 1)]\n",
      "safeti         1              1              [('D000105', 1)]\n",
      "sampl          3              2              [('D000105', 2), ('D000113', 1)]\n",
      "satur          1              1              [('D000106', 1)]\n",
      "scalp          1              1              [('D000104', 1)]\n",
      "scan           1              1              [('D000106', 1)]\n",
      "scar           1              1              [('D000111', 1)]\n",
      "school         1              1              [('D000113', 1)]\n",
      "screen         1              1              [('D000113', 1)]\n",
      "seafood        1              1              [('D000105', 1)]\n",
      "secondari      1              1              [('D000113', 1)]\n",
      "sediment       1              1              [('D000106', 1)]\n",
      "see            2              1              [('D000111', 2)]\n",
      "seen           1              1              [('D000112', 1)]\n",
      "serious        1              1              [('D000105', 1)]\n",
      "serum          1              1              [('D000106', 1)]\n",
      "serv           3              2              [('D000104', 1), ('D000105', 2)]\n",
      "session        1              1              [('D000104', 1)]\n",
      "sever          2              2              [('D000105', 1), ('D000107', 1)]\n",
      "short          1              1              [('D000107', 1)]\n",
      "shortag        1              1              [('D000105', 1)]\n",
      "show           1              1              [('D000113', 1)]\n",
      "shown          1              1              [('D000106', 1)]\n",
      "sign           1              1              [('D000105', 1)]\n",
      "signific       3              3              [('D000105', 1), ('D000111', 1), ('D000113', 1)]\n",
      "similar        2              2              [('D000105', 1), ('D000111', 1)]\n",
      "singl          5              1              [('D000113', 5)]\n",
      "site           3              2              [('D000104', 1), ('D000111', 2)]\n",
      "size           1              1              [('D000113', 1)]\n",
      "skin           2              1              [('D000111', 2)]\n",
      "slow           3              1              [('D000113', 3)]\n",
      "small          1              1              [('D000111', 1)]\n",
      "societ         1              1              [('D000113', 1)]\n",
      "societi        1              1              [('D000113', 1)]\n",
      "soft           1              1              [('D000111', 1)]\n",
      "solubl         1              1              [('D000106', 1)]\n",
      "sourc          1              1              [('D000105', 1)]\n",
      "specif         2              2              [('D000110', 1), ('D000113', 1)]\n",
      "specifi        1              1              [('D000113', 1)]\n",
      "spectroscopi   1              1              [('D000110', 1)]\n",
      "spheric        3              1              [('D000113', 3)]\n",
      "spirit         1              1              [('D000106', 1)]\n",
      "stabl          1              1              [('D000106', 1)]\n",
      "standard       1              1              [('D000113', 1)]\n",
      "start          1              1              [('D000108', 1)]\n",
      "state          1              1              [('D000113', 1)]\n",
      "status         3              2              [('D000105', 2), ('D000106', 1)]\n",
      "stem           1              1              [('D000105', 1)]\n",
      "step           1              1              [('D000111', 1)]\n",
      "stiff          1              1              [('D000106', 1)]\n",
      "still          1              1              [('D000105', 1)]\n",
      "stimul         1              1              [('D000105', 1)]\n",
      "stnfr          2              1              [('D000106', 2)]\n",
      "stoni          1              1              [('D000113', 1)]\n",
      "store          2              1              [('D000110', 2)]\n",
      "strabismus     1              1              [('D000113', 1)]\n",
      "stress         1              1              [('D000106', 1)]\n",
      "stroke         1              1              [('D000108', 1)]\n",
      "studi          28             10             [('D000102', 1), ('D000104', 8), ('D000105', 4), ('D000106', 1), ('D000107', 2), ('D000108', 1), ('D000110', 2), ('D000111', 2), ('D000112', 1), ('D000113', 6)]\n",
      "studiedinclus  1              1              [('D000112', 1)]\n",
      "subcutan       3              1              [('D000105', 3)]\n",
      "subject        13             4              [('D000104', 2), ('D000105', 6), ('D000107', 4), ('D000110', 1)]\n",
      "subjectsinclus 1              1              [('D000105', 1)]\n",
      "subset         1              1              [('D000111', 1)]\n",
      "substanc       2              1              [('D000105', 2)]\n",
      "substanti      2              2              [('D000112', 1), ('D000113', 1)]\n",
      "success        4              1              [('D000111', 4)]\n",
      "suffici        1              1              [('D000111', 1)]\n",
      "sulfasalazin   1              1              [('D000106', 1)]\n",
      "suppli         1              1              [('D000111', 1)]\n",
      "support        1              1              [('D000110', 1)]\n",
      "suppress       1              1              [('D000102', 1)]\n",
      "surgeri        1              1              [('D000111', 1)]\n",
      "surgic         2              2              [('D000111', 1), ('D000113', 1)]\n",
      "surviv         1              1              [('D000105', 1)]\n",
      "swing          1              1              [('D000108', 1)]\n",
      "swollen        1              1              [('D000106', 1)]\n",
      "symptom        1              1              [('D000105', 1)]\n",
      "system         9              2              [('D000105', 7), ('D000106', 2)]\n",
      "take           4              4              [('D000102', 1), ('D000104', 1), ('D000105', 1), ('D000111', 1)]\n",
      "taken          2              1              [('D000111', 2)]\n",
      "targetsthi     1              1              [('D000102', 1)]\n",
      "tcell          3              1              [('D000105', 3)]\n",
      "teach          1              1              [('D000105', 1)]\n",
      "techniqu       2              1              [('D000111', 2)]\n",
      "tender         1              1              [('D000106', 1)]\n",
      "teslath        1              1              [('D000110', 1)]\n",
      "test           6              4              [('D000102', 2), ('D000104', 1), ('D000105', 2), ('D000111', 1)]\n",
      "tetanus        10             1              [('D000105', 10)]\n",
      "th             1              1              [('D000105', 1)]\n",
      "therapeut      2              2              [('D000102', 1), ('D000106', 1)]\n",
      "therapi        1              1              [('D000108', 1)]\n",
      "thimeros       1              1              [('D000105', 1)]\n",
      "three          1              1              [('D000104', 1)]\n",
      "throughout     1              1              [('D000106', 1)]\n",
      "time           3              3              [('D000108', 1), ('D000110', 1), ('D000113', 1)]\n",
      "tissu          11             2              [('D000107', 2), ('D000111', 9)]\n",
      "tnf            3              1              [('D000106', 3)]\n",
      "toler          2              1              [('D000112', 2)]\n",
      "top            3              1              [('D000111', 3)]\n",
      "total          1              1              [('D000104', 1)]\n",
      "toxoid         4              1              [('D000105', 4)]\n",
      "train          7              2              [('D000108', 4), ('D000110', 3)]\n",
      "transplant     1              1              [('D000105', 1)]\n",
      "transport      1              1              [('D000107', 1)]\n",
      "treat          4              4              [('D000102', 1), ('D000105', 1), ('D000106', 1), ('D000113', 1)]\n",
      "treatment      8              4              [('D000102', 1), ('D000105', 3), ('D000106', 2), ('D000113', 2)]\n",
      "tri            3              2              [('D000105', 2), ('D000111', 1)]\n",
      "trial          5              2              [('D000102', 1), ('D000113', 4)]\n",
      "true           1              1              [('D000105', 1)]\n",
      "tube           1              1              [('D000111', 1)]\n",
      "tumor          1              1              [('D000106', 1)]\n",
      "turn           3              3              [('D000102', 1), ('D000104', 1), ('D000111', 1)]\n",
      "two            6              5              [('D000102', 1), ('D000105', 1), ('D000106', 2), ('D000108', 1), ('D000113', 1)]\n",
      "type           3              1              [('D000105', 3)]\n",
      "ultrasonographi1              1              [('D000113', 1)]\n",
      "ultrasonographycorrect1              1              [('D000113', 1)]\n",
      "unclear        1              1              [('D000113', 1)]\n",
      "uncomfort      1              1              [('D000111', 1)]\n",
      "under          1              1              [('D000104', 1)]\n",
      "understand     1              1              [('D000108', 1)]\n",
      "understood     1              1              [('D000108', 1)]\n",
      "univers        3              3              [('D000105', 1), ('D000106', 1), ('D000113', 1)]\n",
      "unsuccess      1              1              [('D000106', 1)]\n",
      "updat          1              1              [('D000113', 1)]\n",
      "us             2              2              [('D000108', 1), ('D000110', 1)]\n",
      "use            16             7              [('D000104', 2), ('D000105', 3), ('D000106', 2), ('D000107', 1), ('D000110', 2), ('D000111', 2), ('D000113', 4)]\n",
      "vaccin         14             1              [('D000105', 14)]\n",
      "vaccinevaccin  1              1              [('D000105', 1)]\n",
      "variabl        1              1              [('D000108', 1)]\n",
      "various        1              1              [('D000104', 1)]\n",
      "veget          1              1              [('D000105', 1)]\n",
      "versus         1              1              [('D000113', 1)]\n",
      "vestibul       1              1              [('D000111', 1)]\n",
      "vg             1              1              [('D000105', 1)]\n",
      "view           1              1              [('D000113', 1)]\n",
      "virus          3              1              [('D000105', 3)]\n",
      "vision         6              1              [('D000113', 6)]\n",
      "visit          1              1              [('D000113', 1)]\n",
      "visual         3              1              [('D000113', 3)]\n",
      "vivo           1              1              [('D000111', 1)]\n",
      "volum          1              1              [('D000106', 1)]\n",
      "volunt         5              3              [('D000105', 3), ('D000110', 1), ('D000111', 1)]\n",
      "voluntari      1              1              [('D000106', 1)]\n",
      "vs             1              1              [('D000102', 1)]\n",
      "wait           1              1              [('D000111', 1)]\n",
      "walk           1              1              [('D000108', 1)]\n",
      "watch          1              1              [('D000104', 1)]\n",
      "water          3              1              [('D000107', 3)]\n",
      "way            1              1              [('D000113', 1)]\n",
      "wbh            3              1              [('D000106', 3)]\n",
      "wear           1              1              [('D000104', 1)]\n",
      "week           2              2              [('D000106', 1), ('D000108', 1)]\n",
      "weekcardiovascular1              1              [('D000108', 1)]\n",
      "weight         2              2              [('D000108', 1), ('D000113', 1)]\n",
      "weightinclus   1              1              [('D000107', 1)]\n",
      "well           4              4              [('D000102', 1), ('D000104', 1), ('D000106', 1), ('D000108', 1)]\n",
      "westergren     1              1              [('D000106', 1)]\n",
      "whether        3              2              [('D000108', 1), ('D000113', 2)]\n",
      "white          1              1              [('D000105', 1)]\n",
      "whole          2              1              [('D000106', 2)]\n",
      "wisconsin      1              1              [('D000106', 1)]\n",
      "within         2              1              [('D000105', 2)]\n",
      "without        5              4              [('D000104', 1), ('D000105', 2), ('D000112', 1), ('D000113', 1)]\n",
      "women          4              3              [('D000104', 1), ('D000105', 1), ('D000108', 2)]\n",
      "womenth        1              1              [('D000108', 1)]\n",
      "work           2              2              [('D000105', 1), ('D000111', 1)]\n",
      "would          3              2              [('D000102', 1), ('D000105', 2)]\n",
      "xl             1              1              [('D000102', 1)]\n",
      "year           4              2              [('D000105', 1), ('D000113', 3)]\n",
      "yet            1              1              [('D000105', 1)]\n",
      "york           1              1              [('D000113', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Displaying it in a table format for the sorted dictionary whihc contains the unique word, Total Frequency and The Document Frequency.\n",
    "print('Word'+'\\t'+'Total Freq'+'\\t'+'Document Freq'+'\\t'+'Posting(Doc-ID, Count)')\n",
    "\n",
    "for key, value in sorted_dict.items():\n",
    "    column1=key\n",
    "    column2 = sum(value.values())\n",
    "    column3 = len(value)\n",
    "    column4 = list(value.items())\n",
    "\n",
    "    print(f\"{ column1:<15}{column2:<15}{column3:<15}{column4}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4523001",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Weighted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "014ab950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a idf dictionary to get the words and the idf values for all the words in the document\n",
    "idf_dict={}\n",
    "N = df_clinical_trial.shape[0]\n",
    "\n",
    "def compute_tfidf(term, doc_id):\n",
    "    tf = sorted_dict[term][doc_id]\n",
    "    idf = math.log2(N / len(sorted_dict[term]))\n",
    "    idf_dict[term]=math.log2(N / len(sorted_dict[term]))\n",
    "    return tf * idf\n",
    "\n",
    "weighted_index = {}\n",
    "for term in sorted_dict:\n",
    "    weighted_index[term] = {}\n",
    "    for doc_id in sorted_dict[term]:\n",
    "        weighted_index[term][doc_id] = compute_tfidf(term, doc_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71c64913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abil': 2.321928094887362,\n",
       " 'acanthosi': 3.321928094887362,\n",
       " 'accommod': 3.321928094887362,\n",
       " 'accord': 2.321928094887362,\n",
       " 'acr': 3.321928094887362,\n",
       " 'acrfor': 3.321928094887362,\n",
       " 'acth': 3.321928094887362,\n",
       " 'activ': 1.736965594166206,\n",
       " 'acuiti': 3.321928094887362,\n",
       " 'acut': 2.321928094887362,\n",
       " 'add': 3.321928094887362,\n",
       " 'addit': 2.321928094887362,\n",
       " 'adequ': 3.321928094887362,\n",
       " 'adher': 3.321928094887362,\n",
       " 'adipos': 3.321928094887362,\n",
       " 'adjuv': 3.321928094887362,\n",
       " 'administ': 3.321928094887362,\n",
       " 'adren': 3.321928094887362,\n",
       " 'adrenocorticotrop': 3.321928094887362,\n",
       " 'adult': 3.321928094887362,\n",
       " 'affect': 3.321928094887362,\n",
       " 'age': 1.3219280948873624,\n",
       " 'agespecif': 3.321928094887362,\n",
       " 'aim': 3.321928094887362,\n",
       " 'allergi': 3.321928094887362,\n",
       " 'allow': 1.736965594166206,\n",
       " 'along': 2.321928094887362,\n",
       " 'alreadi': 3.321928094887362,\n",
       " 'also': 2.321928094887362,\n",
       " 'alter': 3.321928094887362,\n",
       " 'although': 3.321928094887362,\n",
       " 'american': 3.321928094887362,\n",
       " 'among': 3.321928094887362,\n",
       " 'anecdot': 3.321928094887362,\n",
       " 'anim': 3.321928094887362,\n",
       " 'anisometropia': 3.321928094887362,\n",
       " 'annual': 3.321928094887362,\n",
       " 'anoth': 3.321928094887362,\n",
       " 'antagonist': 3.321928094887362,\n",
       " 'anticip': 3.321928094887362,\n",
       " 'antiinflammatori': 3.321928094887362,\n",
       " 'antirheumat': 3.321928094887362,\n",
       " 'appli': 3.321928094887362,\n",
       " 'applic': 3.321928094887362,\n",
       " 'approach': 3.321928094887362,\n",
       " 'approv': 3.321928094887362,\n",
       " 'area': 3.321928094887362,\n",
       " 'aris': 3.321928094887362,\n",
       " 'arm': 2.321928094887362,\n",
       " 'arthriti': 3.321928094887362,\n",
       " 'ascan': 3.321928094887362,\n",
       " 'asian': 3.321928094887362,\n",
       " 'ask': 3.321928094887362,\n",
       " 'assess': 2.321928094887362,\n",
       " 'assign': 2.321928094887362,\n",
       " 'astigmat': 3.321928094887362,\n",
       " 'athlet': 3.321928094887362,\n",
       " 'attach': 3.321928094887362,\n",
       " 'attack': 3.321928094887362,\n",
       " 'attain': 3.321928094887362,\n",
       " 'attent': 3.321928094887362,\n",
       " 'attenu': 3.321928094887362,\n",
       " 'autorefract': 3.321928094887362,\n",
       " 'avail': 3.321928094887362,\n",
       " 'axi': 3.321928094887362,\n",
       " 'axial': 3.321928094887362,\n",
       " 'azathioprin': 3.321928094887362,\n",
       " 'back': 3.321928094887362,\n",
       " 'base': 3.321928094887362,\n",
       " 'baselin': 2.321928094887362,\n",
       " 'basi': 3.321928094887362,\n",
       " 'basic': 3.321928094887362,\n",
       " 'becom': 3.321928094887362,\n",
       " 'begin': 3.321928094887362,\n",
       " 'behavior': 3.321928094887362,\n",
       " 'better': 3.321928094887362,\n",
       " 'beyond': 3.321928094887362,\n",
       " 'bifoc': 3.321928094887362,\n",
       " 'biolog': 3.321928094887362,\n",
       " 'biosyn': 3.321928094887362,\n",
       " 'birmingham': 3.321928094887362,\n",
       " 'birth': 3.321928094887362,\n",
       " 'blind': 3.321928094887362,\n",
       " 'blood': 1.0,\n",
       " 'blur': 3.321928094887362,\n",
       " 'bm': 3.321928094887362,\n",
       " 'bmi': 3.321928094887362,\n",
       " 'bodi': 1.0,\n",
       " 'bone': 3.321928094887362,\n",
       " 'boost': 3.321928094887362,\n",
       " 'boston': 3.321928094887362,\n",
       " 'bout': 3.321928094887362,\n",
       " 'breath': 3.321928094887362,\n",
       " 'brook': 3.321928094887362,\n",
       " 'burden': 3.321928094887362,\n",
       " 'burn': 3.321928094887362,\n",
       " 'cah': 3.321928094887362,\n",
       " 'cahcongenit': 3.321928094887362,\n",
       " 'cahinclus': 3.321928094887362,\n",
       " 'calcium': 2.321928094887362,\n",
       " 'call': 3.321928094887362,\n",
       " 'calori': 3.321928094887362,\n",
       " 'cancer': 3.321928094887362,\n",
       " 'candid': 3.321928094887362,\n",
       " 'carbohydr': 3.321928094887362,\n",
       " 'cardiac': 3.321928094887362,\n",
       " 'cardiovascular': 2.321928094887362,\n",
       " 'carri': 3.321928094887362,\n",
       " 'caus': 3.321928094887362,\n",
       " 'cell': 2.321928094887362,\n",
       " 'cellular': 3.321928094887362,\n",
       " 'center': 3.321928094887362,\n",
       " 'centigrad': 3.321928094887362,\n",
       " 'certain': 3.321928094887362,\n",
       " 'chair': 3.321928094887362,\n",
       " 'chanc': 3.321928094887362,\n",
       " 'chang': 1.0,\n",
       " 'channel': 3.321928094887362,\n",
       " 'character': 3.321928094887362,\n",
       " 'chd': 3.321928094887362,\n",
       " 'chemotherapi': 3.321928094887362,\n",
       " 'child': 3.321928094887362,\n",
       " 'childbear': 3.321928094887362,\n",
       " 'children': 1.3219280948873624,\n",
       " 'childrenth': 3.321928094887362,\n",
       " 'chronic': 2.321928094887362,\n",
       " 'circumst': 3.321928094887362,\n",
       " 'citi': 3.321928094887362,\n",
       " 'class': 3.321928094887362,\n",
       " 'clear': 3.321928094887362,\n",
       " 'clinic': 1.736965594166206,\n",
       " 'close': 3.321928094887362,\n",
       " 'clot': 3.321928094887362,\n",
       " 'cognit': 3.321928094887362,\n",
       " 'collabor': 3.321928094887362,\n",
       " 'colleg': 2.321928094887362,\n",
       " 'comet': 3.321928094887362,\n",
       " 'cometto': 3.321928094887362,\n",
       " 'committe': 3.321928094887362,\n",
       " 'common': 3.321928094887362,\n",
       " 'compar': 1.736965594166206,\n",
       " 'comparison': 3.321928094887362,\n",
       " 'complet': 3.321928094887362,\n",
       " 'complic': 3.321928094887362,\n",
       " 'compon': 2.321928094887362,\n",
       " 'compos': 3.321928094887362,\n",
       " 'composit': 3.321928094887362,\n",
       " 'compositesth': 3.321928094887362,\n",
       " 'comput': 3.321928094887362,\n",
       " 'concept': 3.321928094887362,\n",
       " 'condit': 3.321928094887362,\n",
       " 'confirm': 3.321928094887362,\n",
       " 'congenit': 2.321928094887362,\n",
       " 'consent': 3.321928094887362,\n",
       " 'consequ': 3.321928094887362,\n",
       " 'consist': 2.321928094887362,\n",
       " 'consum': 3.321928094887362,\n",
       " 'contact': 3.321928094887362,\n",
       " 'content': 3.321928094887362,\n",
       " 'contribut': 3.321928094887362,\n",
       " 'control': 2.321928094887362,\n",
       " 'convent': 3.321928094887362,\n",
       " 'converg': 3.321928094887362,\n",
       " 'coordin': 3.321928094887362,\n",
       " 'correct': 3.321928094887362,\n",
       " 'corticosteroid': 3.321928094887362,\n",
       " 'cosmet': 3.321928094887362,\n",
       " 'cost': 3.321928094887362,\n",
       " 'could': 2.321928094887362,\n",
       " 'countri': 3.321928094887362,\n",
       " 'cours': 2.321928094887362,\n",
       " 'crc': 3.321928094887362,\n",
       " 'creactiv': 3.321928094887362,\n",
       " 'criteria': 0.0,\n",
       " 'critic': 3.321928094887362,\n",
       " 'crossov': 3.321928094887362,\n",
       " 'crosssect': 3.321928094887362,\n",
       " 'current': 3.321928094887362,\n",
       " 'cvd': 3.321928094887362,\n",
       " 'cvdinclus': 3.321928094887362,\n",
       " 'cyanot': 3.321928094887362,\n",
       " 'cyclopleg': 3.321928094887362,\n",
       " 'cytokin': 3.321928094887362,\n",
       " 'day': 2.321928094887362,\n",
       " 'death': 3.321928094887362,\n",
       " 'decilit': 3.321928094887362,\n",
       " 'decreas': 3.321928094887362,\n",
       " 'defect': 3.321928094887362,\n",
       " 'defin': 3.321928094887362,\n",
       " 'degre': 3.321928094887362,\n",
       " 'dehydr': 3.321928094887362,\n",
       " 'deleteri': 3.321928094887362,\n",
       " 'delin': 2.321928094887362,\n",
       " 'dental': 3.321928094887362,\n",
       " 'deplet': 3.321928094887362,\n",
       " 'deriv': 3.321928094887362,\n",
       " 'describ': 3.321928094887362,\n",
       " 'design': 3.321928094887362,\n",
       " 'detect': 3.321928094887362,\n",
       " 'determin': 2.321928094887362,\n",
       " 'develop': 1.0,\n",
       " 'development': 3.321928094887362,\n",
       " 'developmentinn': 3.321928094887362,\n",
       " 'diabet': 3.321928094887362,\n",
       " 'diagnos': 3.321928094887362,\n",
       " 'diagnosi': 3.321928094887362,\n",
       " 'diet': 3.321928094887362,\n",
       " 'dietari': 3.321928094887362,\n",
       " 'differ': 1.3219280948873624,\n",
       " 'dilat': 3.321928094887362,\n",
       " 'dip': 3.321928094887362,\n",
       " 'direct': 3.321928094887362,\n",
       " 'discomfort': 3.321928094887362,\n",
       " 'diseas': 1.0,\n",
       " 'diseaseadult': 3.321928094887362,\n",
       " 'diseasecongenit': 3.321928094887362,\n",
       " 'diseasemodifi': 3.321928094887362,\n",
       " 'diseasesrec': 3.321928094887362,\n",
       " 'distanc': 3.321928094887362,\n",
       " 'dobutamin': 3.321928094887362,\n",
       " 'document': 3.321928094887362,\n",
       " 'done': 3.321928094887362,\n",
       " 'dosag': 2.321928094887362,\n",
       " 'dose': 3.321928094887362,\n",
       " 'dosedepend': 3.321928094887362,\n",
       " 'doubleblind': 3.321928094887362,\n",
       " 'doublemask': 3.321928094887362,\n",
       " 'drug': 2.321928094887362,\n",
       " 'ecg': 3.321928094887362,\n",
       " 'echo': 3.321928094887362,\n",
       " 'effect': 0.7369655941662062,\n",
       " 'efficaci': 2.321928094887362,\n",
       " 'effort': 3.321928094887362,\n",
       " 'eight': 3.321928094887362,\n",
       " 'either': 3.321928094887362,\n",
       " 'electrod': 3.321928094887362,\n",
       " 'electrolyt': 3.321928094887362,\n",
       " 'electrophysiolog': 3.321928094887362,\n",
       " 'elev': 2.321928094887362,\n",
       " 'elig': 1.736965594166206,\n",
       " 'eligiblerheumat': 3.321928094887362,\n",
       " 'employ': 3.321928094887362,\n",
       " 'endpoint': 3.321928094887362,\n",
       " 'endur': 3.321928094887362,\n",
       " 'endurancetrain': 3.321928094887362,\n",
       " 'energi': 3.321928094887362,\n",
       " 'england': 3.321928094887362,\n",
       " 'enrol': 2.321928094887362,\n",
       " 'entail': 3.321928094887362,\n",
       " 'entri': 3.321928094887362,\n",
       " 'environ': 3.321928094887362,\n",
       " 'epidem': 3.321928094887362,\n",
       " 'equal': 2.321928094887362,\n",
       " 'equival': 3.321928094887362,\n",
       " 'erp': 3.321928094887362,\n",
       " 'error': 3.321928094887362,\n",
       " 'erythrocyt': 3.321928094887362,\n",
       " 'especi': 3.321928094887362,\n",
       " 'etiolog': 3.321928094887362,\n",
       " 'evalu': 1.736965594166206,\n",
       " 'even': 3.321928094887362,\n",
       " 'eventrel': 3.321928094887362,\n",
       " 'everi': 3.321928094887362,\n",
       " 'ex': 3.321928094887362,\n",
       " 'examin': 2.321928094887362,\n",
       " 'exampl': 3.321928094887362,\n",
       " 'excess': 3.321928094887362,\n",
       " 'exclud': 3.321928094887362,\n",
       " 'exclus': 1.736965594166206,\n",
       " 'exercis': 1.736965594166206,\n",
       " 'expect': 2.321928094887362,\n",
       " 'expens': 3.321928094887362,\n",
       " 'experi': 2.321928094887362,\n",
       " 'extend': 3.321928094887362,\n",
       " 'extent': 3.321928094887362,\n",
       " 'extramur': 3.321928094887362,\n",
       " 'extrem': 3.321928094887362,\n",
       " 'eye': 3.321928094887362,\n",
       " 'factor': 3.321928094887362,\n",
       " 'factorreceptor': 3.321928094887362,\n",
       " 'famili': 3.321928094887362,\n",
       " 'fashion': 3.321928094887362,\n",
       " 'fat': 1.736965594166206,\n",
       " 'fatfre': 3.321928094887362,\n",
       " 'febril': 3.321928094887362,\n",
       " 'femal': 2.321928094887362,\n",
       " 'fev': 3.321928094887362,\n",
       " 'fibrinogen': 3.321928094887362,\n",
       " 'fight': 3.321928094887362,\n",
       " 'find': 2.321928094887362,\n",
       " 'flare': 3.321928094887362,\n",
       " 'focus': 3.321928094887362,\n",
       " 'follow': 1.736965594166206,\n",
       " 'followup': 1.736965594166206,\n",
       " 'forc': 3.321928094887362,\n",
       " 'foreign': 3.321928094887362,\n",
       " 'form': 3.321928094887362,\n",
       " 'four': 1.736965594166206,\n",
       " 'frank': 3.321928094887362,\n",
       " 'frequent': 3.321928094887362,\n",
       " 'fulfil': 3.321928094887362,\n",
       " 'function': 1.736965594166206,\n",
       " 'furthermor': 3.321928094887362,\n",
       " 'gase': 3.321928094887362,\n",
       " 'gender': 3.321928094887362,\n",
       " 'general': 2.321928094887362,\n",
       " 'get': 3.321928094887362,\n",
       " 'give': 3.321928094887362,\n",
       " 'given': 3.321928094887362,\n",
       " 'glucocorticoid': 3.321928094887362,\n",
       " 'glucos': 3.321928094887362,\n",
       " 'go': 3.321928094887362,\n",
       " 'goal': 1.736965594166206,\n",
       " 'gold': 3.321928094887362,\n",
       " 'good': 1.3219280948873624,\n",
       " 'gotten': 3.321928094887362,\n",
       " 'graft': 3.321928094887362,\n",
       " 'gram': 3.321928094887362,\n",
       " 'grant': 3.321928094887362,\n",
       " 'great': 3.321928094887362,\n",
       " 'greater': 3.321928094887362,\n",
       " 'group': 3.321928094887362,\n",
       " 'grow': 3.321928094887362,\n",
       " 'growth': 3.321928094887362,\n",
       " 'gum': 3.321928094887362,\n",
       " 'health': 1.3219280948873624,\n",
       " 'healthi': 1.736965594166206,\n",
       " 'healthobes': 3.321928094887362,\n",
       " 'heart': 1.736965594166206,\n",
       " 'heat': 3.321928094887362,\n",
       " 'heavi': 3.321928094887362,\n",
       " 'high': 2.321928094887362,\n",
       " 'histolog': 3.321928094887362,\n",
       " 'histori': 1.3219280948873624,\n",
       " 'hormon': 2.321928094887362,\n",
       " 'hour': 2.321928094887362,\n",
       " 'houston': 3.321928094887362,\n",
       " 'howev': 3.321928094887362,\n",
       " 'hpa': 3.321928094887362,\n",
       " 'human': 2.321928094887362,\n",
       " 'hydroxychloroquinin': 3.321928094887362,\n",
       " 'hyperinsulinemia': 3.321928094887362,\n",
       " 'hyperplasia': 3.321928094887362,\n",
       " 'hypersensit': 3.321928094887362,\n",
       " 'hyperthermia': 3.321928094887362,\n",
       " 'hypothalamicpituitaryadren': 3.321928094887362,\n",
       " 'hypothes': 3.321928094887362,\n",
       " 'hypothesi': 3.321928094887362,\n",
       " 'identifi': 3.321928094887362,\n",
       " 'ii': 2.321928094887362,\n",
       " 'iii': 3.321928094887362,\n",
       " 'il': 3.321928094887362,\n",
       " 'ill': 3.321928094887362,\n",
       " 'imag': 3.321928094887362,\n",
       " 'iml': 3.321928094887362,\n",
       " 'immun': 3.321928094887362,\n",
       " 'impair': 2.321928094887362,\n",
       " 'implant': 3.321928094887362,\n",
       " 'import': 2.321928094887362,\n",
       " 'improv': 3.321928094887362,\n",
       " 'includ': 1.3219280948873624,\n",
       " 'inclus': 3.321928094887362,\n",
       " 'increas': 1.3219280948873624,\n",
       " 'index': 2.321928094887362,\n",
       " 'individu': 3.321928094887362,\n",
       " 'induc': 3.321928094887362,\n",
       " 'induct': 3.321928094887362,\n",
       " 'inelig': 3.321928094887362,\n",
       " 'infect': 3.321928094887362,\n",
       " 'influenc': 3.321928094887362,\n",
       " 'inform': 2.321928094887362,\n",
       " 'inher': 3.321928094887362,\n",
       " 'inhibitor': 3.321928094887362,\n",
       " 'inject': 3.321928094887362,\n",
       " 'input': 3.321928094887362,\n",
       " 'insulin': 2.321928094887362,\n",
       " 'intens': 3.321928094887362,\n",
       " 'intercurr': 3.321928094887362,\n",
       " 'interest': 3.321928094887362,\n",
       " 'interfer': 3.321928094887362,\n",
       " 'interleukin': 3.321928094887362,\n",
       " 'interv': 3.321928094887362,\n",
       " 'intervent': 2.321928094887362,\n",
       " 'intoler': 3.321928094887362,\n",
       " 'intracel': 3.321928094887362,\n",
       " 'intramuscular': 2.321928094887362,\n",
       " 'intraor': 3.321928094887362,\n",
       " 'investig': 2.321928094887362,\n",
       " 'involv': 2.321928094887362,\n",
       " 'isa': 3.321928094887362,\n",
       " 'issu': 3.321928094887362,\n",
       " 'joint': 3.321928094887362,\n",
       " 'juvenileonset': 3.321928094887362,\n",
       " 'karnofski': 3.321928094887362,\n",
       " 'keratin': 3.321928094887362,\n",
       " 'kgheight': 3.321928094887362,\n",
       " 'kill': 3.321928094887362,\n",
       " 'klh': 3.321928094887362,\n",
       " 'know': 3.321928094887362,\n",
       " 'lack': 2.321928094887362,\n",
       " 'lactat': 3.321928094887362,\n",
       " 'larger': 2.321928094887362,\n",
       " 'last': 3.321928094887362,\n",
       " 'ldlcholesterol': 3.321928094887362,\n",
       " 'lead': 1.3219280948873624,\n",
       " 'lean': 2.321928094887362,\n",
       " 'learn': 3.321928094887362,\n",
       " 'least': 1.736965594166206,\n",
       " 'leav': 3.321928094887362,\n",
       " 'length': 3.321928094887362,\n",
       " 'lens': 3.321928094887362,\n",
       " 'lenseschildren': 3.321928094887362,\n",
       " 'less': 1.736965594166206,\n",
       " 'level': 1.3219280948873624,\n",
       " 'lifelong': 3.321928094887362,\n",
       " 'like': 1.736965594166206,\n",
       " 'limit': 3.321928094887362,\n",
       " 'line': 3.321928094887362,\n",
       " 'link': 3.321928094887362,\n",
       " 'lip': 3.321928094887362,\n",
       " 'lipid': 3.321928094887362,\n",
       " 'liver': 2.321928094887362,\n",
       " 'local': 2.321928094887362,\n",
       " 'longer': 3.321928094887362,\n",
       " 'longitudin': 3.321928094887362,\n",
       " 'longterm': 3.321928094887362,\n",
       " 'lose': 3.321928094887362,\n",
       " 'loss': 3.321928094887362,\n",
       " 'lowfat': 3.321928094887362,\n",
       " 'magnet': 3.321928094887362,\n",
       " 'magnitud': 3.321928094887362,\n",
       " 'make': 3.321928094887362,\n",
       " 'male': 3.321928094887362,\n",
       " 'mani': 3.321928094887362,\n",
       " 'marrow': 3.321928094887362,\n",
       " 'mass': 2.321928094887362,\n",
       " 'match': 2.321928094887362,\n",
       " 'maximum': 2.321928094887362,\n",
       " 'may': 1.736965594166206,\n",
       " 'mcg': 3.321928094887362,\n",
       " 'measur': 0.7369655941662062,\n",
       " 'measuresinclus': 3.321928094887362,\n",
       " 'mechan': 3.321928094887362,\n",
       " 'medic': 2.321928094887362,\n",
       " 'meet': 3.321928094887362,\n",
       " 'mellitus': 3.321928094887362,\n",
       " 'memori': 3.321928094887362,\n",
       " 'mercuri': 3.321928094887362,\n",
       " 'met': 3.321928094887362,\n",
       " 'metabol': 2.321928094887362,\n",
       " 'method': 3.321928094887362,\n",
       " 'methodolog': 3.321928094887362,\n",
       " 'methotrex': 3.321928094887362,\n",
       " 'mg': 2.321928094887362,\n",
       " 'mgdl': 3.321928094887362,\n",
       " 'mice': 3.321928094887362,\n",
       " 'might': 3.321928094887362,\n",
       " 'minday': 3.321928094887362,\n",
       " 'minneapoli': 3.321928094887362,\n",
       " 'minnesota': 2.321928094887362,\n",
       " 'minut': 3.321928094887362,\n",
       " 'ml': 3.321928094887362,\n",
       " 'mm': 3.321928094887362,\n",
       " 'model': 3.321928094887362,\n",
       " 'moderatefat': 3.321928094887362,\n",
       " 'monitor': 3.321928094887362,\n",
       " 'mono': 3.321928094887362,\n",
       " 'mononucleosi': 3.321928094887362,\n",
       " 'montanid': 3.321928094887362,\n",
       " 'month': 1.736965594166206,\n",
       " 'morn': 3.321928094887362,\n",
       " 'mother': 3.321928094887362,\n",
       " 'mouth': 3.321928094887362,\n",
       " 'mrs': 3.321928094887362,\n",
       " 'much': 3.321928094887362,\n",
       " 'mucos': 3.321928094887362,\n",
       " 'mucosa': 3.321928094887362,\n",
       " 'muga': 3.321928094887362,\n",
       " 'multicent': 2.321928094887362,\n",
       " 'multimodel': 3.321928094887362,\n",
       " 'must': 2.321928094887362,\n",
       " 'mvv': 3.321928094887362,\n",
       " 'myopia': 3.321928094887362,\n",
       " 'narcot': 3.321928094887362,\n",
       " 'nation': 3.321928094887362,\n",
       " 'natruret': 3.321928094887362,\n",
       " 'natur': 3.321928094887362,\n",
       " 'nearsighted': 3.321928094887362,\n",
       " 'necessari': 3.321928094887362,\n",
       " 'necrosi': 3.321928094887362,\n",
       " 'need': 2.321928094887362,\n",
       " 'neighborhood': 3.321928094887362,\n",
       " 'neurolog': 3.321928094887362,\n",
       " 'neuropsycholog': 3.321928094887362,\n",
       " 'new': 3.321928094887362,\n",
       " 'next': 3.321928094887362,\n",
       " 'nifedipin': 3.321928094887362,\n",
       " 'nigrican': 3.321928094887362,\n",
       " 'nih': 3.321928094887362,\n",
       " 'noncyanot': 3.321928094887362,\n",
       " 'noninvas': 3.321928094887362,\n",
       " 'nonsteroid': 3.321928094887362,\n",
       " 'nontox': 3.321928094887362,\n",
       " 'normal': 2.321928094887362,\n",
       " 'nsaid': 3.321928094887362,\n",
       " 'number': 3.321928094887362,\n",
       " 'obes': 2.321928094887362,\n",
       " 'obesityinclus': 3.321928094887362,\n",
       " 'observ': 3.321928094887362,\n",
       " 'occurr': 3.321928094887362,\n",
       " 'offspringlead': 3.321928094887362,\n",
       " 'often': 3.321928094887362,\n",
       " 'older': 3.321928094887362,\n",
       " 'one': 2.321928094887362,\n",
       " 'open': 3.321928094887362,\n",
       " 'optim': 3.321928094887362,\n",
       " 'optometri': 3.321928094887362,\n",
       " 'oral': 2.321928094887362,\n",
       " 'order': 3.321928094887362,\n",
       " 'organ': 3.321928094887362,\n",
       " 'outcom': 3.321928094887362,\n",
       " 'outsid': 3.321928094887362,\n",
       " 'overal': 3.321928094887362,\n",
       " 'overburden': 3.321928094887362,\n",
       " 'oxygen': 2.321928094887362,\n",
       " 'pain': 2.321928094887362,\n",
       " 'pal': 3.321928094887362,\n",
       " 'palat': 3.321928094887362,\n",
       " 'parallel': 3.321928094887362,\n",
       " 'part': 3.321928094887362,\n",
       " 'particip': 1.736965594166206,\n",
       " 'past': 3.321928094887362,\n",
       " 'patient': 1.3219280948873624,\n",
       " 'pattern': 3.321928094887362,\n",
       " 'penicillamin': 3.321928094887362,\n",
       " 'peopl': 3.321928094887362,\n",
       " 'peptid': 3.321928094887362,\n",
       " 'per': 3.321928094887362,\n",
       " 'perform': 1.736965594166206,\n",
       " 'period': 1.736965594166206,\n",
       " 'permit': 3.321928094887362,\n",
       " 'person': 2.321928094887362,\n",
       " 'phase': 2.321928094887362,\n",
       " 'philadelphia': 3.321928094887362,\n",
       " 'phillip': 3.321928094887362,\n",
       " 'physic': 3.321928094887362,\n",
       " 'physiolog': 3.321928094887362,\n",
       " 'piec': 3.321928094887362,\n",
       " 'pilot': 3.321928094887362,\n",
       " 'place': 2.321928094887362,\n",
       " 'placebo': 3.321928094887362,\n",
       " 'placebocontrol': 3.321928094887362,\n",
       " 'plasma': 3.321928094887362,\n",
       " 'plasminogen': 3.321928094887362,\n",
       " 'po': 3.321928094887362,\n",
       " 'poison': 3.321928094887362,\n",
       " 'portion': 3.321928094887362,\n",
       " 'posit': 3.321928094887362,\n",
       " 'post': 3.321928094887362,\n",
       " 'postexercis': 3.321928094887362,\n",
       " 'postmenopaus': 3.321928094887362,\n",
       " 'potenti': 2.321928094887362,\n",
       " 'practition': 3.321928094887362,\n",
       " 'preclud': 3.321928094887362,\n",
       " 'predict': 2.321928094887362,\n",
       " 'prefer': 3.321928094887362,\n",
       " 'pregnanc': 3.321928094887362,\n",
       " 'pregnant': 2.321928094887362,\n",
       " 'prepar': 3.321928094887362,\n",
       " 'prescript': 3.321928094887362,\n",
       " 'present': 2.321928094887362,\n",
       " 'pressur': 1.736965594166206,\n",
       " 'preval': 2.321928094887362,\n",
       " 'prevent': 2.321928094887362,\n",
       " 'primari': 3.321928094887362,\n",
       " 'prior': 3.321928094887362,\n",
       " 'proanp': 3.321928094887362,\n",
       " 'proatrial': 3.321928094887362,\n",
       " 'problem': 2.321928094887362,\n",
       " 'procardia': 3.321928094887362,\n",
       " 'procedur': 3.321928094887362,\n",
       " 'produc': 3.321928094887362,\n",
       " 'product': 3.321928094887362,\n",
       " 'program': 3.321928094887362,\n",
       " 'progress': 3.321928094887362,\n",
       " 'prolong': 3.321928094887362,\n",
       " 'proport': 3.321928094887362,\n",
       " 'protect': 3.321928094887362,\n",
       " 'protein': 2.321928094887362,\n",
       " 'protocol': 1.3219280948873624,\n",
       " 'protocolcanc': 3.321928094887362,\n",
       " 'protocolmyopia': 3.321928094887362,\n",
       " 'provid': 1.736965594166206,\n",
       " 'public': 3.321928094887362,\n",
       " 'purpos': 1.0,\n",
       " 'quantif': 3.321928094887362,\n",
       " 'questionmouth': 3.321928094887362,\n",
       " 'random': 2.321928094887362,\n",
       " 'rang': 3.321928094887362,\n",
       " 'rate': 1.3219280948873624,\n",
       " 'rational': 3.321928094887362,\n",
       " 'reach': 3.321928094887362,\n",
       " 'reason': 3.321928094887362,\n",
       " 'receiv': 1.736965594166206,\n",
       " 'receptor': 3.321928094887362,\n",
       " 'receptorsinclus': 3.321928094887362,\n",
       " 'recipi': 3.321928094887362,\n",
       " 'recommend': 3.321928094887362,\n",
       " 'record': 2.321928094887362,\n",
       " 'recoveri': 3.321928094887362,\n",
       " 'recruit': 2.321928094887362,\n",
       " 'recurr': 3.321928094887362,\n",
       " 'reduc': 1.736965594166206,\n",
       " 'referr': 3.321928094887362,\n",
       " 'refract': 3.321928094887362,\n",
       " 'relaps': 3.321928094887362,\n",
       " 'relat': 3.321928094887362,\n",
       " 'relationship': 3.321928094887362,\n",
       " 'releas': 2.321928094887362,\n",
       " 'releasedinclus': 3.321928094887362,\n",
       " 'remain': 3.321928094887362,\n",
       " 'rememb': 3.321928094887362,\n",
       " 'remiss': 3.321928094887362,\n",
       " 'renal': 3.321928094887362,\n",
       " 'replac': 2.321928094887362,\n",
       " 'replenish': 3.321928094887362,\n",
       " 'report': 3.321928094887362,\n",
       " 'requir': 1.3219280948873624,\n",
       " 'research': 1.3219280948873624,\n",
       " 'resist': 2.321928094887362,\n",
       " 'reson': 3.321928094887362,\n",
       " 'respect': 3.321928094887362,\n",
       " 'respiratori': 3.321928094887362,\n",
       " 'respond': 3.321928094887362,\n",
       " 'respons': 1.736965594166206,\n",
       " 'responsesth': 3.321928094887362,\n",
       " 'rest': 3.321928094887362,\n",
       " 'result': 2.321928094887362,\n",
       " 'rheumatoid': 3.321928094887362,\n",
       " 'rheumatolog': 3.321928094887362,\n",
       " 'risk': 2.321928094887362,\n",
       " 'role': 3.321928094887362,\n",
       " 'rule': 3.321928094887362,\n",
       " 'run': 3.321928094887362,\n",
       " 'safe': 3.321928094887362,\n",
       " 'safeti': 3.321928094887362,\n",
       " 'sampl': 2.321928094887362,\n",
       " 'satur': 3.321928094887362,\n",
       " 'scalp': 3.321928094887362,\n",
       " 'scan': 3.321928094887362,\n",
       " 'scar': 3.321928094887362,\n",
       " 'school': 3.321928094887362,\n",
       " 'screen': 3.321928094887362,\n",
       " 'seafood': 3.321928094887362,\n",
       " 'secondari': 3.321928094887362,\n",
       " 'sediment': 3.321928094887362,\n",
       " 'see': 3.321928094887362,\n",
       " 'seen': 3.321928094887362,\n",
       " 'serious': 3.321928094887362,\n",
       " 'serum': 3.321928094887362,\n",
       " 'serv': 2.321928094887362,\n",
       " 'session': 3.321928094887362,\n",
       " 'sever': 2.321928094887362,\n",
       " 'short': 3.321928094887362,\n",
       " 'shortag': 3.321928094887362,\n",
       " 'show': 3.321928094887362,\n",
       " 'shown': 3.321928094887362,\n",
       " 'sign': 3.321928094887362,\n",
       " 'signific': 1.736965594166206,\n",
       " 'similar': 2.321928094887362,\n",
       " 'singl': 3.321928094887362,\n",
       " 'site': 2.321928094887362,\n",
       " 'size': 3.321928094887362,\n",
       " 'skin': 3.321928094887362,\n",
       " 'slow': 3.321928094887362,\n",
       " 'small': 3.321928094887362,\n",
       " 'societ': 3.321928094887362,\n",
       " 'societi': 3.321928094887362,\n",
       " 'soft': 3.321928094887362,\n",
       " 'solubl': 3.321928094887362,\n",
       " 'sourc': 3.321928094887362,\n",
       " 'specif': 2.321928094887362,\n",
       " 'specifi': 3.321928094887362,\n",
       " 'spectroscopi': 3.321928094887362,\n",
       " 'spheric': 3.321928094887362,\n",
       " 'spirit': 3.321928094887362,\n",
       " 'stabl': 3.321928094887362,\n",
       " 'standard': 3.321928094887362,\n",
       " 'start': 3.321928094887362,\n",
       " 'state': 3.321928094887362,\n",
       " 'status': 2.321928094887362,\n",
       " 'stem': 3.321928094887362,\n",
       " 'step': 3.321928094887362,\n",
       " 'stiff': 3.321928094887362,\n",
       " 'still': 3.321928094887362,\n",
       " 'stimul': 3.321928094887362,\n",
       " 'stnfr': 3.321928094887362,\n",
       " 'stoni': 3.321928094887362,\n",
       " 'store': 3.321928094887362,\n",
       " 'strabismus': 3.321928094887362,\n",
       " 'stress': 3.321928094887362,\n",
       " 'stroke': 3.321928094887362,\n",
       " 'studi': 0.0,\n",
       " 'studiedinclus': 3.321928094887362,\n",
       " 'subcutan': 3.321928094887362,\n",
       " 'subject': 1.3219280948873624,\n",
       " 'subjectsinclus': 3.321928094887362,\n",
       " 'subset': 3.321928094887362,\n",
       " 'substanc': 3.321928094887362,\n",
       " 'substanti': 2.321928094887362,\n",
       " 'success': 3.321928094887362,\n",
       " 'suffici': 3.321928094887362,\n",
       " 'sulfasalazin': 3.321928094887362,\n",
       " 'suppli': 3.321928094887362,\n",
       " 'support': 3.321928094887362,\n",
       " 'suppress': 3.321928094887362,\n",
       " 'surgeri': 3.321928094887362,\n",
       " 'surgic': 2.321928094887362,\n",
       " 'surviv': 3.321928094887362,\n",
       " 'swing': 3.321928094887362,\n",
       " 'swollen': 3.321928094887362,\n",
       " 'symptom': 3.321928094887362,\n",
       " 'system': 2.321928094887362,\n",
       " 'take': 1.3219280948873624,\n",
       " 'taken': 3.321928094887362,\n",
       " 'targetsthi': 3.321928094887362,\n",
       " 'tcell': 3.321928094887362,\n",
       " 'teach': 3.321928094887362,\n",
       " 'techniqu': 3.321928094887362,\n",
       " 'tender': 3.321928094887362,\n",
       " 'teslath': 3.321928094887362,\n",
       " 'test': 1.3219280948873624,\n",
       " 'tetanus': 3.321928094887362,\n",
       " 'th': 3.321928094887362,\n",
       " 'therapeut': 2.321928094887362,\n",
       " 'therapi': 3.321928094887362,\n",
       " 'thimeros': 3.321928094887362,\n",
       " 'three': 3.321928094887362,\n",
       " 'throughout': 3.321928094887362,\n",
       " 'time': 1.736965594166206,\n",
       " 'tissu': 2.321928094887362,\n",
       " 'tnf': 3.321928094887362,\n",
       " 'toler': 3.321928094887362,\n",
       " 'top': 3.321928094887362,\n",
       " 'total': 3.321928094887362,\n",
       " 'toxoid': 3.321928094887362,\n",
       " 'train': 2.321928094887362,\n",
       " 'transplant': 3.321928094887362,\n",
       " 'transport': 3.321928094887362,\n",
       " 'treat': 1.3219280948873624,\n",
       " 'treatment': 1.3219280948873624,\n",
       " 'tri': 2.321928094887362,\n",
       " 'trial': 2.321928094887362,\n",
       " 'true': 3.321928094887362,\n",
       " 'tube': 3.321928094887362,\n",
       " 'tumor': 3.321928094887362,\n",
       " 'turn': 1.736965594166206,\n",
       " 'two': 1.0,\n",
       " 'type': 3.321928094887362,\n",
       " 'ultrasonographi': 3.321928094887362,\n",
       " 'ultrasonographycorrect': 3.321928094887362,\n",
       " 'unclear': 3.321928094887362,\n",
       " 'uncomfort': 3.321928094887362,\n",
       " 'under': 3.321928094887362,\n",
       " 'understand': 3.321928094887362,\n",
       " 'understood': 3.321928094887362,\n",
       " 'univers': 1.736965594166206,\n",
       " 'unsuccess': 3.321928094887362,\n",
       " 'updat': 3.321928094887362,\n",
       " 'us': 2.321928094887362,\n",
       " 'use': 0.5145731728297582,\n",
       " 'vaccin': 3.321928094887362,\n",
       " 'vaccinevaccin': 3.321928094887362,\n",
       " 'variabl': 3.321928094887362,\n",
       " 'various': 3.321928094887362,\n",
       " 'veget': 3.321928094887362,\n",
       " 'versus': 3.321928094887362,\n",
       " 'vestibul': 3.321928094887362,\n",
       " 'vg': 3.321928094887362,\n",
       " 'view': 3.321928094887362,\n",
       " 'virus': 3.321928094887362,\n",
       " 'vision': 3.321928094887362,\n",
       " 'visit': 3.321928094887362,\n",
       " 'visual': 3.321928094887362,\n",
       " 'vivo': 3.321928094887362,\n",
       " 'volum': 3.321928094887362,\n",
       " 'volunt': 1.736965594166206,\n",
       " 'voluntari': 3.321928094887362,\n",
       " 'vs': 3.321928094887362,\n",
       " 'wait': 3.321928094887362,\n",
       " 'walk': 3.321928094887362,\n",
       " 'watch': 3.321928094887362,\n",
       " 'water': 3.321928094887362,\n",
       " 'way': 3.321928094887362,\n",
       " 'wbh': 3.321928094887362,\n",
       " 'wear': 3.321928094887362,\n",
       " 'week': 2.321928094887362,\n",
       " 'weekcardiovascular': 3.321928094887362,\n",
       " 'weight': 2.321928094887362,\n",
       " 'weightinclus': 3.321928094887362,\n",
       " 'well': 1.3219280948873624,\n",
       " 'westergren': 3.321928094887362,\n",
       " 'whether': 2.321928094887362,\n",
       " 'white': 3.321928094887362,\n",
       " 'whole': 3.321928094887362,\n",
       " 'wisconsin': 3.321928094887362,\n",
       " 'within': 3.321928094887362,\n",
       " 'without': 1.3219280948873624,\n",
       " 'women': 1.736965594166206,\n",
       " 'womenth': 3.321928094887362,\n",
       " 'work': 2.321928094887362,\n",
       " 'would': 2.321928094887362,\n",
       " 'xl': 3.321928094887362,\n",
       " 'year': 2.321928094887362,\n",
       " 'yet': 3.321928094887362,\n",
       " 'york': 3.321928094887362}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we have idf values for our dataset \n",
    "idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae31465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_expand(query, num_words=5, threshold=0.5):\n",
    "    # Finding the top 5 similar words for the given query \n",
    "    # Here we are wxpanding the query based on Synonymns and the Goooglenews we have imported before.\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # Find most similar words using Word2Vec\n",
    "    similar_words = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            sim_words = word2vec_model.similar_by_word(token, topn=num_words)\n",
    "            similar_words.extend([w[0] for w in sim_words if w[1] > threshold])\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    # Combine original query with similar words\n",
    "    expanded_query = ' '.join(tokens + similar_words)\n",
    "    # This gives us the most similar words.\n",
    "    return expanded_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e4c360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function does the pre-processing of the data where it removeds punctuations, stop words and does stemming\n",
    "def userquery(query):\n",
    "    query_idf={}\n",
    "    query=re.sub(r'≥|µ|\\d+', '', query).translate(translator).lower().split()\n",
    "\n",
    "    filtered_words = [word for word in query if word not in stopwords and len(word) > 1]\n",
    "\n",
    "    \n",
    "    stemming = snowball.SnowballStemmer('english')\n",
    "    stemming_wwrds = [stemming.stem(x) for x in filtered_words]\n",
    "    for i in stemming_wwrds:\n",
    "        if i in idf_dict.keys():\n",
    "            query_idf[i]=idf_dict[i]\n",
    "        else:\n",
    "             pass\n",
    "    # Final Query DataFrame having query words and its respective IDF values.\n",
    "    return query_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35af355e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'present': 2.321928094887362,\n",
       " 'progress': 3.321928094887362,\n",
       " 'sever': 2.321928094887362,\n",
       " 'function': 1.736965594166206,\n",
       " 'pressur': 1.736965594166206,\n",
       " 'clinic': 1.736965594166206,\n",
       " 'toler': 3.321928094887362,\n",
       " 'evalu': 1.736965594166206,\n",
       " 'echo': 3.321928094887362,\n",
       " 'confirm': 3.321928094887362,\n",
       " 'critic': 3.321928094887362,\n",
       " 'show': 3.321928094887362,\n",
       " 'dilat': 3.321928094887362,\n",
       " 'under': 3.321928094887362,\n",
       " 'patient': 1.3219280948873624,\n",
       " 'replac': 2.321928094887362,\n",
       " 'scan': 3.321928094887362,\n",
       " 'us': 2.321928094887362,\n",
       " 'also': 2.321928094887362,\n",
       " 'cardiac': 3.321928094887362,\n",
       " 'heart': 1.736965594166206,\n",
       " 'diseas': 1.0,\n",
       " 'serious': 3.321928094887362,\n",
       " 'alreadi': 3.321928094887362,\n",
       " 'prior': 3.321928094887362,\n",
       " 'anoth': 3.321928094887362,\n",
       " 'last': 3.321928094887362,\n",
       " 'import': 2.321928094887362,\n",
       " 'shown': 3.321928094887362,\n",
       " 'leav': 3.321928094887362,\n",
       " 'respiratori': 3.321928094887362,\n",
       " 'addit': 2.321928094887362,\n",
       " 'howev': 3.321928094887362,\n",
       " 'cardiovascular': 2.321928094887362,\n",
       " 'assess': 2.321928094887362,\n",
       " 'examin': 2.321928094887362}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking our imlementaiton of expanded and user query function\n",
    "expandedquery=word2vec_expand(q, num_words=5, threshold=0.5)\n",
    "q=userquery(expandedquery)\n",
    "# Here we have the vector representation of the query\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2432b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to calculate the document length for its repsective documents and document ids for all similairites.\n",
    "def doclength(similarity):\n",
    "    doc_length={}\n",
    "    #Document Lenght for Cosine Similarity\n",
    "    if similarity.lower()=='cosine':\n",
    "        for key, value in sorted_dict.items():\n",
    "            for document in value.keys():\n",
    "                if document not in doc_length:\n",
    "                    doc_length[document]=(sorted_dict[key][document]*idf_dict[key])**2\n",
    "                else:\n",
    "                    doc_length[document]+=(sorted_dict[key][document]*idf_dict[key])**2\n",
    "        for key in doc_length:\n",
    "            doc_length[key] = math.sqrt(doc_length[key])\n",
    "    else:\n",
    "        #Document Length for Jaccard and Dice Similarity \n",
    "        for key, value in sorted_dict.items():\n",
    "            for document in value.keys():\n",
    "                if document not in doc_length:\n",
    "                    doc_length[document]=(sorted_dict[key][document]*idf_dict[key])**2\n",
    "                else:\n",
    "                    doc_length[document]+=(sorted_dict[key][document]*idf_dict[key])**2\n",
    "        for key in doc_length:\n",
    "            doc_length[key] = np.sum(doc_length[key])\n",
    "        \n",
    "    return doc_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcd1a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries length for its respective similarity\n",
    "\n",
    "def querieslength(q,similarity):\n",
    "    sum_queries_length=0\n",
    "    # Cosine\n",
    "    if similarity.lower()=='cosine':\n",
    "        for key in q:\n",
    "            sum_queries_length+= (idf_dict[key])**2\n",
    "        sum_queries_length=math.sqrt(sum_queries_length)\n",
    "    # Jaccard or Dice\n",
    "    elif similarity.lower()=='jaccard' or similarity.lower()=='dice':\n",
    "        for key in q:\n",
    "            sum_queries_length+= (idf_dict[key])**2\n",
    "        sum_queries_length=np.sum(sum_queries_length)      \n",
    "    # This gives us the square root of sum of squares of idf values for cosine and np.sum for Jaccard or Dice\n",
    "    return sum_queries_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7bd3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function runs iteratively for all the different similarities and gives us the final df with all the similarities \n",
    "#of the query and the documents.\n",
    "def similar_documents(q):\n",
    "    similarities=[\"Cosine\" , 'Jaccard' , 'Dice']\n",
    "    diff_similarity_df = pd.DataFrame(columns=[\"Cosine\" , 'Jaccard' , 'Dice'])\n",
    "    dictionaries_list=[]\n",
    "    for i in similarities:\n",
    "        document_ids= list(df_clinical_trial['nct_id'])\n",
    "        document_dict = {document: 0 for document in document_ids}\n",
    "\n",
    "        for term in q:\n",
    "    #run for all the terms in the query\n",
    "            for key in sorted_dict[term].keys():\n",
    "            #Numerator\n",
    "                document_dict[key]+=(sorted_dict[term][key]*idf_dict[term])*(1*idf_dict[term])\n",
    "        for key in document_dict:\n",
    "            if key in doclength(i):\n",
    "                #Cosine Similairty of Queries and Documents\n",
    "                if i.lower()=='cosine':\n",
    "                    document_dict[key] = document_dict[key]/(querieslength(q,i)*doclength(i)[key])\n",
    "\n",
    "                elif i.lower()=='dice':\n",
    "                     #Dice Similairty of Queries and Documents\n",
    "                    document_dict[key] = 2*document_dict[key]/(querieslength(q,i)*doclength(i)[key])\n",
    "                else:\n",
    "                     #Jaccard Similairty of Queries and Documents\n",
    "                    document_dict[key] = document_dict[key]/((querieslength(q,i)*doclength(i)[key])-document_dict[key])\n",
    "        dictionaries_list.append(document_dict)\n",
    "\n",
    "    diff_similarity_df = pd.DataFrame.from_dict(dictionaries_list )\n",
    "    diff_similarity_df=diff_similarity_df.T\n",
    "    diff_similarity_df.columns = similarities\n",
    "    return diff_similarity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68cd3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is just to get the brief title from the original df and the respective similairyt with document ID.\n",
    "def documents_contents(similarity,q):\n",
    "    diff_1 = similar_documents(q)\n",
    "    diff_1 = diff_1[(diff_1 != 0).any(axis=1)].reset_index()\n",
    "    diff_2 = df_clinical_trial\n",
    "    df_doc_contents = pd.merge(diff_1 , diff_2 , left_on='index' , right_on='nct_id')\n",
    "    df_doc_contents=df_doc_contents.rename(columns={'index':'Document ID'})\n",
    "    df_doc_contents=df_doc_contents[['Document ID' , 'Cosine' , 'Jaccard','Dice' , 'brief_title']]\n",
    "    similarity=similarity.capitalize()\n",
    "    df_doc_contents=df_doc_contents.sort_values(by=similarity ,ascending=False)[['Document ID' ,similarity, 'brief_title']].reset_index(drop=True)\n",
    "    return df_doc_contents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "919c23d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document ID</th>\n",
       "      <th>Cosine</th>\n",
       "      <th>brief_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D000106</td>\n",
       "      <td>0.144860</td>\n",
       "      <td>41.8 Degree Centigrade Whole Body Hyperthermia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D000113</td>\n",
       "      <td>0.130760</td>\n",
       "      <td>Correction of Myopia Evaluation Trial (COMET)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D000111</td>\n",
       "      <td>0.074940</td>\n",
       "      <td>Intraoral Grafting of Ex Vivo Produced Oral Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D000104</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>Does Lead Burden Alter Neuropsychological Deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D000108</td>\n",
       "      <td>0.052024</td>\n",
       "      <td>Effects of Training Intensity on the CHD Risk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D000112</td>\n",
       "      <td>0.046971</td>\n",
       "      <td>Prevalence of Carbohydrate Intolerance in Lean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D000102</td>\n",
       "      <td>0.046934</td>\n",
       "      <td>Congenital Adrenal Hyperplasia: Calcium Channe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D000107</td>\n",
       "      <td>0.046167</td>\n",
       "      <td>Body Water Content in Cyanotic Congenital Hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D000105</td>\n",
       "      <td>0.036725</td>\n",
       "      <td>Vaccination With Tetanus and KLH to Assess Imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D000110</td>\n",
       "      <td>0.016063</td>\n",
       "      <td>Influence of Diet and Endurance Running on Int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document ID    Cosine                                        brief_title\n",
       "0     D000106  0.144860  41.8 Degree Centigrade Whole Body Hyperthermia...\n",
       "1     D000113  0.130760      Correction of Myopia Evaluation Trial (COMET)\n",
       "2     D000111  0.074940  Intraoral Grafting of Ex Vivo Produced Oral Mu...\n",
       "3     D000104  0.052333  Does Lead Burden Alter Neuropsychological Deve...\n",
       "4     D000108  0.052024  Effects of Training Intensity on the CHD Risk ...\n",
       "5     D000112  0.046971  Prevalence of Carbohydrate Intolerance in Lean...\n",
       "6     D000102  0.046934  Congenital Adrenal Hyperplasia: Calcium Channe...\n",
       "7     D000107  0.046167  Body Water Content in Cyanotic Congenital Hear...\n",
       "8     D000105  0.036725  Vaccination With Tetanus and KLH to Assess Imm...\n",
       "9     D000110  0.016063  Influence of Diet and Endurance Running on Int..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 Cosine Similar Documents\n",
    "documents_contents('COSINE',q).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bcb5eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document ID</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>brief_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D000106</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>41.8 Degree Centigrade Whole Body Hyperthermia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D000112</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>Prevalence of Carbohydrate Intolerance in Lean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D000107</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>Body Water Content in Cyanotic Congenital Hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D000108</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>Effects of Training Intensity on the CHD Risk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D000111</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>Intraoral Grafting of Ex Vivo Produced Oral Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D000113</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>Correction of Myopia Evaluation Trial (COMET)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D000104</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>Does Lead Burden Alter Neuropsychological Deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D000102</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>Congenital Adrenal Hyperplasia: Calcium Channe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D000105</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>Vaccination With Tetanus and KLH to Assess Imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D000110</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>Influence of Diet and Endurance Running on Int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document ID   Jaccard                                        brief_title\n",
       "0     D000106  0.000165  41.8 Degree Centigrade Whole Body Hyperthermia...\n",
       "1     D000112  0.000100  Prevalence of Carbohydrate Intolerance in Lean...\n",
       "2     D000107  0.000084  Body Water Content in Cyanotic Congenital Hear...\n",
       "3     D000108  0.000083  Effects of Training Intensity on the CHD Risk ...\n",
       "4     D000111  0.000080  Intraoral Grafting of Ex Vivo Produced Oral Mu...\n",
       "5     D000113  0.000076      Correction of Myopia Evaluation Trial (COMET)\n",
       "6     D000104  0.000075  Does Lead Burden Alter Neuropsychological Deve...\n",
       "7     D000102  0.000061  Congenital Adrenal Hyperplasia: Calcium Channe...\n",
       "8     D000105  0.000021  Vaccination With Tetanus and KLH to Assess Imm...\n",
       "9     D000110  0.000019  Influence of Diet and Endurance Running on Int..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 Jaccard Similarity Documents\n",
    "documents_contents('Jaccard',q).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6665dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document ID</th>\n",
       "      <th>Dice</th>\n",
       "      <th>brief_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D000106</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>41.8 Degree Centigrade Whole Body Hyperthermia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D000112</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>Prevalence of Carbohydrate Intolerance in Lean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D000107</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>Body Water Content in Cyanotic Congenital Hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D000108</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>Effects of Training Intensity on the CHD Risk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D000111</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>Intraoral Grafting of Ex Vivo Produced Oral Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D000113</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>Correction of Myopia Evaluation Trial (COMET)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D000104</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>Does Lead Burden Alter Neuropsychological Deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D000102</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>Congenital Adrenal Hyperplasia: Calcium Channe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D000105</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>Vaccination With Tetanus and KLH to Assess Imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D000110</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>Influence of Diet and Endurance Running on Int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document ID      Dice                                        brief_title\n",
       "0     D000106  0.000329  41.8 Degree Centigrade Whole Body Hyperthermia...\n",
       "1     D000112  0.000200  Prevalence of Carbohydrate Intolerance in Lean...\n",
       "2     D000107  0.000167  Body Water Content in Cyanotic Congenital Hear...\n",
       "3     D000108  0.000166  Effects of Training Intensity on the CHD Risk ...\n",
       "4     D000111  0.000161  Intraoral Grafting of Ex Vivo Produced Oral Mu...\n",
       "5     D000113  0.000152      Correction of Myopia Evaluation Trial (COMET)\n",
       "6     D000104  0.000150  Does Lead Burden Alter Neuropsychological Deve...\n",
       "7     D000102  0.000121  Congenital Adrenal Hyperplasia: Calcium Channe...\n",
       "8     D000105  0.000042  Vaccination With Tetanus and KLH to Assess Imm...\n",
       "9     D000110  0.000037  Influence of Diet and Endurance Running on Int..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 Dice Similarity Documents\n",
    "documents_contents('DICE',q).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97ee96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comverting the Query to a dataframe where rest of the words are filled with zero except query terms\n",
    "def query_df(q):\n",
    "    df_query1 = pd.DataFrame(columns=list(sorted_dict.keys()))\n",
    "\n",
    "    # Populate the DataFrame with the values from the given dictionary\n",
    "    for key, value in q.items():\n",
    "        if key in df_query1.columns:\n",
    "            df_query1.loc[0, key] = value\n",
    "\n",
    "    # Fill missing values with zeroes\n",
    "    df_query1 = df_query1.fillna(0)\n",
    "    return df_query1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72d847ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the sorted dictionary to a pandas df\n",
    "def rawtm_df():\n",
    "    df_rawterms = pd.DataFrame.from_dict(sorted_dict, orient='index')\n",
    "    df_rawterms=df_rawterms.fillna(0)\n",
    "    df_rawterms=df_rawterms.T\n",
    "    df_rawterms=df_rawterms.reindex(sorted(df_rawterms.columns), axis=1)\n",
    "    return df_rawterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6a4a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using relevance judments we are expanding the query.\n",
    "def modify_query(Q, R, NR, alpha = 0.5, beta= 0.25) :\n",
    "    # getting the Q document\n",
    "    df_rawterms=rawtm_df()\n",
    "    query_docs=rawtm_df().copy()\n",
    "    query_words=query_docs.copy()\n",
    "    new_row = pd.Series(Q, name='Q' , index=query_words.columns)\n",
    "    query_words = query_words.append(new_row)\n",
    "    # getting the relevant documents\n",
    "    for i in R:\n",
    "        new_row = pd.Series(df_rawterms.loc[i], name='R' , index=query_words.columns)\n",
    "        query_words = query_words.append(new_row)\n",
    "    relevance_docs=query_words.loc['R']\n",
    "    average_relavance=relevance_docs.mean()\n",
    "    # getting the non relevant documents.\n",
    "    for i in NR:\n",
    "        new_row = pd.Series(df_rawterms.loc[i], name='NR' , index=query_words.columns)\n",
    "        query_words = query_words.append(new_row)\n",
    "    nonrelevance_docs=query_words.loc['NR']\n",
    "    average_nonrelavance=nonrelevance_docs.mean()\n",
    "    Q1 = query_words.loc['Q'] + (alpha *average_relavance ) - (beta *average_nonrelavance)\n",
    "    queries_tm = pd.DataFrame()\n",
    "\n",
    "    queries_tm['Q'] =  query_words.loc['Q']\n",
    "    queries_tm['Q1'] =  Q1\n",
    "    queries_tm=queries_tm.T\n",
    "    queries_tm.iloc[queries_tm < 0] = 0\n",
    "    return queries_tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cfa9777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>acanthosi</th>\n",
       "      <th>accommod</th>\n",
       "      <th>accord</th>\n",
       "      <th>acr</th>\n",
       "      <th>acrfor</th>\n",
       "      <th>acth</th>\n",
       "      <th>activ</th>\n",
       "      <th>acuiti</th>\n",
       "      <th>acut</th>\n",
       "      <th>...</th>\n",
       "      <th>within</th>\n",
       "      <th>without</th>\n",
       "      <th>women</th>\n",
       "      <th>womenth</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>xl</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 816 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        abil  acanthosi  accommod    accord       acr    acrfor      acth  \\\n",
       "Q   0.000000        0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "Q1  0.333333        0.0  0.166667  0.333333  0.166667  0.166667  0.333333   \n",
       "\n",
       "    activ    acuiti      acut  ...  within   without  women  womenth  work  \\\n",
       "Q    0.00  0.000000  0.000000  ...     0.0  0.000000    0.0      0.0   0.0   \n",
       "Q1   0.25  0.166667  0.166667  ...     0.0  0.083333    0.0      0.0   0.0   \n",
       "\n",
       "       would        xl  year  yet      york  \n",
       "Q   0.000000  0.000000   0.0  0.0  0.000000  \n",
       "Q1  0.166667  0.166667   0.5  0.0  0.166667  \n",
       "\n",
       "[2 rows x 816 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the new query for all the Relevant and Non-Relvant documents\n",
    "Q=list(query_df(q).iloc[0])\n",
    "R = ['D000106','D000113','D000102']\n",
    "NR =['D000111','D000104','D000108']\n",
    "alpha = 0.5\n",
    "beta = 0.25\n",
    "query_result = modify_query(Q, R, NR, alpha, beta)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db17cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increased columns: Index(['abil', 'accommod', 'accord', 'acr', 'acrfor', 'acth', 'activ',\n",
      "       'acuiti', 'acut', 'addit',\n",
      "       ...\n",
      "       'well', 'westergren', 'whether', 'whole', 'wisconsin', 'without',\n",
      "       'would', 'xl', 'year', 'york'],\n",
      "      dtype='object', length=393)\n",
      "Decreased columns: Index(['alreadi', 'anoth', 'howev', 'leav', 'replac', 'under', 'us'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get the difference between rows 1 and 2\n",
    "query_resultdiff = query_result.iloc[1] - query_result.iloc[0]\n",
    "\n",
    "# Create a mask for positive and negative values\n",
    "positive_mask = query_resultdiff > 0\n",
    "negative_mask = query_resultdiff < 0\n",
    "                                                                \n",
    "# Get the columns where values have increased and decreased\n",
    "increased_cols = query_resultdiff[positive_mask].index\n",
    "decreased_cols = query_resultdiff[negative_mask].index\n",
    "\n",
    "print(\"Increased columns:\", increased_cols)\n",
    "print(\"Decreased columns:\", decreased_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a6023fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Cosine similairity of Documnets and the two Queries (old and new)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "Q_cosinesimilarity = cosine_similarity(query_result.loc['Q'].to_frame().T , rawtm_df()).flatten()\n",
    "Q1_cosinesimilarity = cosine_similarity(query_result.loc['Q1'].to_frame().T , rawtm_df()).flatten()\n",
    "data = {'Q': Q_cosinesimilarity, 'Q1': Q1_cosinesimilarity}\n",
    "sim_documents = pd.DataFrame(data)\n",
    "sim_documents=sim_documents.set_index(rawtm_df().index)\n",
    "sim_documents=sim_documents.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a28a5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D000102</th>\n",
       "      <th>D000105</th>\n",
       "      <th>D000112</th>\n",
       "      <th>D000113</th>\n",
       "      <th>D000106</th>\n",
       "      <th>D000107</th>\n",
       "      <th>D000108</th>\n",
       "      <th>D000111</th>\n",
       "      <th>D000104</th>\n",
       "      <th>D000110</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>0.067448</td>\n",
       "      <td>0.050727</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.138264</td>\n",
       "      <td>0.147527</td>\n",
       "      <td>0.062618</td>\n",
       "      <td>0.064020</td>\n",
       "      <td>0.084142</td>\n",
       "      <td>0.045236</td>\n",
       "      <td>0.021961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>0.232333</td>\n",
       "      <td>0.104838</td>\n",
       "      <td>0.074813</td>\n",
       "      <td>0.428722</td>\n",
       "      <td>0.324805</td>\n",
       "      <td>0.091931</td>\n",
       "      <td>0.089033</td>\n",
       "      <td>0.105036</td>\n",
       "      <td>0.088853</td>\n",
       "      <td>0.053861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     D000102   D000105   D000112   D000113   D000106   D000107   D000108  \\\n",
       "Q   0.067448  0.050727  0.036615  0.138264  0.147527  0.062618  0.064020   \n",
       "Q1  0.232333  0.104838  0.074813  0.428722  0.324805  0.091931  0.089033   \n",
       "\n",
       "     D000111   D000104   D000110  \n",
       "Q   0.084142  0.045236  0.021961  \n",
       "Q1  0.105036  0.088853  0.053861  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity of document and the query.\n",
    "sim_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "708b37c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increased columns: Index(['abil', 'accommod', 'accord', 'acr', 'acrfor', 'acth', 'activ',\n",
      "       'acuiti', 'acut', 'addit',\n",
      "       ...\n",
      "       'well', 'westergren', 'whether', 'whole', 'wisconsin', 'without',\n",
      "       'would', 'xl', 'year', 'york'],\n",
      "      dtype='object', length=393)\n",
      "Decreased columns: Index(['alreadi', 'anoth', 'howev', 'leav', 'replac', 'under', 'us'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "query_resultdiff = query_result.iloc[1] - query_result.iloc[0]\n",
    "\n",
    "# Create a mask for positive and negative values\n",
    "positive_mask = query_resultdiff > 0\n",
    "negative_mask = query_resultdiff < 0\n",
    "                                                                \n",
    "# Get the columns where values have increased and decreased\n",
    "increased_cols = query_resultdiff[positive_mask].index\n",
    "decreased_cols = query_resultdiff[negative_mask].index\n",
    "\n",
    "print(\"Increased columns:\", increased_cols)\n",
    "print(\"Decreased columns:\", decreased_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81e124",
   "metadata": {},
   "source": [
    "## GUI Application for Search Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c2d4bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"R:\\ANACONDA\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"R:\\ANACONDA\\lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_button.py\", line 553, in _clicked\n",
      "    self._command()\n",
      "  File \"C:\\Users\\ABDULR~1\\AppData\\Local\\Temp/ipykernel_3168/3886248279.py\", line 124, in <lambda>\n",
      "    delbutton = customtkinter.CTkButton(master=root, text=\"Clear the Output\", command=lambda: [mydelete()] ,fg_color=\"red\")\n",
      "  File \"C:\\Users\\ABDULR~1\\AppData\\Local\\Temp/ipykernel_3168/3886248279.py\", line 58, in mydelete\n",
      "    if cosine_label is not None:\n",
      "NameError: name 'cosine_label' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"R:\\ANACONDA\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"R:\\ANACONDA\\lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_button.py\", line 553, in _clicked\n",
      "    self._command()\n",
      "  File \"C:\\Users\\ABDULR~1\\AppData\\Local\\Temp/ipykernel_3168/3886248279.py\", line 124, in <lambda>\n",
      "    delbutton = customtkinter.CTkButton(master=root, text=\"Clear the Output\", command=lambda: [mydelete()] ,fg_color=\"red\")\n",
      "  File \"C:\\Users\\ABDULR~1\\AppData\\Local\\Temp/ipykernel_3168/3886248279.py\", line 61, in mydelete\n",
      "    if jaccard_label is not None:\n",
      "NameError: name 'jaccard_label' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"R:\\ANACONDA\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"R:\\ANACONDA\\lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_button.py\", line 553, in _clicked\n",
      "    self._command()\n",
      "  File \"C:\\Users\\ABDULR~1\\AppData\\Local\\Temp/ipykernel_3168/3886248279.py\", line 124, in <lambda>\n",
      "    delbutton = customtkinter.CTkButton(master=root, text=\"Clear the Output\", command=lambda: [mydelete()] ,fg_color=\"red\")\n",
      "  File \"C:\\Users\\ABDULR~1\\AppData\\Local\\Temp/ipykernel_3168/3886248279.py\", line 64, in mydelete\n",
      "    if dice_label is not None:\n",
      "NameError: name 'dice_label' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Importing Respective Modules to run our GUI.\n",
    "import tkinter as tk\n",
    "import customtkinter\n",
    "from tabulate import tabulate\n",
    "customtkinter.set_appearance_mode(\"dark\") \n",
    "customtkinter.set_default_color_theme(\"dark-blue\")  \n",
    "root = customtkinter.CTk()\n",
    "root.geometry(\"1024x600\")\n",
    "# TextBox to get our Input Query\n",
    "entry = customtkinter.CTkTextbox(master=root, width=400,height=200 )\n",
    "entry.pack()\n",
    "\n",
    "textbox = customtkinter.CTkTextbox(master=root , width=350)\n",
    "textbox.pack()\n",
    "# Creating a label for the text box of input query.\n",
    "label = customtkinter.CTkLabel(master=root, text=\"Enter your Input Query in the Textbox\")\n",
    "label.place(relx=0.08, rely=0.1)\n",
    "label.configure(text_color='orange')\n",
    "# Creating a label for Relevant Documents\n",
    "label1 = customtkinter.CTkLabel(master=root, text=\"Relevant Documents\")\n",
    "label1.place(x=780,y=2)\n",
    "label1.configure(text_color='orange')\n",
    "# Creating an Entry box for Relevant documents\n",
    "entry2=customtkinter.CTkEntry(master=root, width=300,placeholder_text=\"Enter your relevant docs seperated by comma\")\n",
    "entry2.pack()\n",
    "entry2.place(x=720,y=25)\n",
    "# Creating an Label for Non-Relevant Documents\n",
    "label2 = customtkinter.CTkLabel(master=root, text=\"Non-Relevant Documents\")\n",
    "label2.place(x=780,y=60)\n",
    "label2.configure(text_color='orange')\n",
    "# Creating an Entry box for Non-Relevant documents\n",
    "entry3=customtkinter.CTkEntry(master=root, width=300,placeholder_text=\"Enter your non-rel docs seperated by comma\")\n",
    "entry3.pack()\n",
    "entry3.place(x=720,y=85)\n",
    "\n",
    "# Creating a label for our random queries generated.\n",
    "\n",
    "label4 = customtkinter.CTkLabel(master=root, text=\"Random Sample Query to give in Input Query.\")\n",
    "label4.place(x=20,y=350)\n",
    "label4.configure(text_color='orange')\n",
    "# Converting a df row to a string to show the sample query.\n",
    "table = str((queries_topics().sample(n=1).to_string(index=False))).replace('\\n', ' ').replace('\\t', ' ').replace('-',\"\").replace('Queries',\"\").strip()\n",
    "textbox.configure(text_color='white')\n",
    "textbox.insert(\"2.0\", table)\n",
    "textbox.pack(padx=20, pady=250)\n",
    "textbox.place(x=10,y=380)\n",
    " # THe output of the modified query\n",
    "textbox2 = customtkinter.CTkTextbox(master=root , width=250)\n",
    "textbox2.configure(fg_color='transparent' , text_color='white')\n",
    "textbox2.pack()\n",
    "\n",
    "def mydelete():\n",
    "    # Clear the outputs from all the generated outputs\n",
    "    global output_label, cosine_label, jaccard_label, dice_label\n",
    "    if output_label is not None:\n",
    "        output_label.destroy()\n",
    "        output_label = None\n",
    "    if cosine_label is not None:\n",
    "        cosine_label.destroy()\n",
    "        cosine_label = None\n",
    "    if jaccard_label is not None:\n",
    "        jaccard_label.destroy()\n",
    "        jaccard_label = None\n",
    "    if dice_label is not None:\n",
    "        dice_label.destroy()\n",
    "        dice_label = None\n",
    "\n",
    "def query_modifier():\n",
    "    # This function generated the modifed query having necessary terms to modify the query\n",
    "    # This also takes the inut from the user for Releavnt and Non-Relevant terms\n",
    "    R=entry2.get().split(',')\n",
    "    NR = entry3.get().split(',')\n",
    "    Q=tk_query\n",
    "    newquery_result = modify_query(Q, R, NR, alpha = 0.5, beta= 0.25)\n",
    "    query_resultdiff = newquery_result.iloc[1] - newquery_result.iloc[0]\n",
    "    positive_mask = query_resultdiff > 0\n",
    "    increased_cols = query_resultdiff[positive_mask].index\n",
    "#     print(\"Increased columns:\", increased_cols)\n",
    "    textbox2.insert(\"0.0\", f'After Query Expansion using Rocchio Method you can modify your vocabulary using these words {increased_cols.tolist()}' )\n",
    "   \n",
    "    textbox2.place(x=720,y=150)\n",
    "#     query_modifier_msg = tk.Message(master=root , text=increased_cols  )\n",
    "#     query_modifier_msg.pack(padx=20, pady=20)\n",
    "#     query_modifier_msg.place(x=850,y=200 )\n",
    "        \n",
    "def myclick():\n",
    "    # this funcaiton gets the query from the user and gives us the similar documents for all similarities\n",
    "    global output_label\n",
    "    global tk_query\n",
    "    value1=entry.get(\"0.0\", \"end\")\n",
    "    expanded_query=word2vec_expand(value1, num_words=5, threshold=0.5)\n",
    "    tk_query=userquery(expanded_query)\n",
    "    output_label = tk.Message(master=root , text=similar_documents(tk_query).iloc[:10].to_string())\n",
    "    output_label.pack(padx=10, pady=10)\n",
    "    output_label.place(x=550,y=400 )\n",
    "\n",
    "def topcosine():\n",
    "    # Gives us the Cosine similar documents\n",
    "    global cosine_label\n",
    "    cosine_label = tk.Message(master=root , text=documents_contents('COSINE',tk_query).iloc[:10].to_string() ,  width=1700)\n",
    "    cosine_label.pack(padx=20, pady=20)\n",
    "    cosine_label.place(x=450,y=400 )\n",
    "\n",
    "def topjaccard():\n",
    "    # Gives us the Jaccard similar documents\n",
    "    global jaccard_label\n",
    "    jaccard_label = tk.Message(master=root , text=documents_contents('JACCARD',tk_query).iloc[:10].to_string() ,  width=1700)\n",
    "    jaccard_label.pack(padx=20, pady=20)\n",
    "    jaccard_label.place(x=450,y=400 )\n",
    "\n",
    "def topdice():\n",
    "    ## Gives us the Dice similar documents\n",
    "    global dice_label\n",
    "    dice_label = tk.Message(master=root , text=documents_contents('DICE',tk_query).iloc[:10].to_string() ,  width=1700)\n",
    "    dice_label.pack(padx=20, pady=20)\n",
    "    dice_label.place(x=450,y=400 )\n",
    "\n",
    "\n",
    "#Button for Top Documents for all Similairties\n",
    "button = customtkinter.CTkButton(master=root, text=\"Get the top documents for all similarities\", command=myclick)\n",
    "button.pack()\n",
    "button.place(x=25, y=230)\n",
    "#Delete Button to clear the output.\n",
    "delbutton = customtkinter.CTkButton(master=root, text=\"Clear the Output\", command=lambda: [mydelete()] ,fg_color=\"red\")\n",
    "delbutton.pack()\n",
    "delbutton.place(x=390, y=205)\n",
    "#Cosine Button to get the top 10 similar documents .\n",
    "cosinebutton = customtkinter.CTkButton(master=root, text=\"Get the cosine values\", command=topcosine)\n",
    "cosinebutton.pack()\n",
    "cosinebutton.place(x=25, y=260)\n",
    "#Jaccard Button to get the top 10 similar documents .\n",
    "jacdelbutton = customtkinter.CTkButton(master=root, text=\"Get the Jaccard values\", command=topjaccard)\n",
    "jacdelbutton.pack()\n",
    "jacdelbutton.place(x=25, y=290)\n",
    "#Get the output of Modified Query to get increased terms/ terms to be added to the query.\n",
    "querymodifierbutton = customtkinter.CTkButton(master=root, text=\"Modify your query\", command=query_modifier)\n",
    "querymodifierbutton.pack()\n",
    "querymodifierbutton.place(x=725, y=130)\n",
    "\n",
    "\n",
    "#Dice Button to get the top 10 similar documents .\n",
    "dicebutton = customtkinter.CTkButton(master=root, text=\"Get the dice values\", command=topdice)\n",
    "dicebutton.pack()\n",
    "dicebutton.place(x=25, y=320)\n",
    "\n",
    "# Close the tkinter module.\n",
    "def on_closing():\n",
    "    root.quit()\n",
    "    root.destroy()\n",
    "\n",
    "# Set the function to be called when the window is closed\n",
    "root.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "\n",
    "\n",
    "root.mainloop()\n",
    "# root.destroy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa945e",
   "metadata": {},
   "source": [
    "## Evaluation of our Search Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bebba4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the Med Line Corpus Dataset\n",
    "#Getting an reference on how to read the data from here\n",
    "#https://github.com/pragmalingu/experiments/blob/master/00_Data/MedlineCorpus.ipynb\n",
    "PATH_TO_MED_TXT = 'MED.ALL'\n",
    "PATH_TO_MED_QRY = 'MED.QRY'\n",
    "PATH_TO_MED_REL = 'MED.REL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae77accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two list for med document and query\n",
    "ID_marker = re.compile('^\\.I',re.MULTILINE)\n",
    "\n",
    "def get_data(PATH_TO_FILE, marker):\n",
    "    with open (PATH_TO_FILE,'r') as f:\n",
    "        text = f.read()\n",
    "        lines = re.split(marker,text)\n",
    "        lines.pop(0)\n",
    "    return lines\n",
    "\n",
    "med_txt_list = get_data(PATH_TO_MED_TXT, ID_marker)\n",
    "med_qry_list = get_data(PATH_TO_MED_QRY, ID_marker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30b5aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hash Map for documents\n",
    "cacm_documents={}\n",
    "for i in range(1,len(med_txt_list)):\n",
    "    cacm_documents[i]=med_txt_list[i-1].replace('\\n','').replace('\\t',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6541492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hash map for queries\n",
    "cacm_queries={}\n",
    "for i in range(1,len(med_qry_list)):\n",
    "    cacm_queries[i]=med_qry_list[i-1].replace('\\n','').replace('\\t',\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c0e1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to remove punctuations, stopwords and stem words\n",
    "def preprocessing_documents1():\n",
    "    df_cacm ={}\n",
    "    # loop through the dictionary and process the values\n",
    "    for key, value in cacm_documents.items():\n",
    "        # Removing the punctuations, numbers and characters.    \n",
    "        value=re.sub(r'≥|µ|\\d+', '', value).translate(translator).lower().split()\n",
    "        #removing stop words\n",
    "        filtered_words = [word for word in value if word not in stopwords and len(word) > 1]\n",
    "        #Stemming of Words\n",
    "        stemming = snowball.SnowballStemmer('english')\n",
    "        stemming_wwrds = [stemming.stem(x) for x in filtered_words]\n",
    "        df_cacm[key] = list(stemming_wwrds)\n",
    "\n",
    "    return df_cacm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "241c13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cacm=preprocessing_documents1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d455bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to remove punctuations, stopwords and stem words\n",
    "def preprocessing_documents2():\n",
    "    df_cacmqueries ={}\n",
    "    # loop through the dictionary and process the values\n",
    "    for key, value in cacm_queries.items():\n",
    "\n",
    "        value=re.sub(r'≥|µ|\\d+', '', value).translate(translator).lower().split()\n",
    "\n",
    "        filtered_words = [word for word in value if word not in stopwords and len(word) > 1]\n",
    "        stemming = snowball.SnowballStemmer('english')\n",
    "        stemming_wwrds = [stemming.stem(x) for x in filtered_words]\n",
    "        df_cacmqueries[key] = list(stemming_wwrds)\n",
    "\n",
    "    return df_cacmqueries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23e4f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cacmqueries=preprocessing_documents2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df2aa8fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating a second dictionary to store the token and the list of documents it is present and the number of occurences\n",
    "def doc_occurences1():\n",
    "    second_dict={}\n",
    "    for key,value in  df_cacm.items():\n",
    "        for i in range(len(value)): # running through each key and its respective value\n",
    "            if value[i] in second_dict:  # checking whether the value is present or not \n",
    "                if key not in second_dict[value[i]].keys(): \n",
    "    # this condition is because when the loop goes to second document id it has to add multiple occurences of a particular word\n",
    "                    second_dict[value[i]][key]=1\n",
    "                else:\n",
    "                    second_dict[value[i]][key]+=1 # else increase the count by 1\n",
    "            else:           \n",
    "                second_dict[value[i]]={key:1} # create a multi level dictionary to add the words , the document id and the ouccrence\n",
    "    return second_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38b6531b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cacmoccur=doc_occurences1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8e7a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = {key: value for key, value in sorted(doc_occurences1().items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3611eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the IDF Values for the documents.\n",
    "idf_dict={}\n",
    "N = len(med_txt_list)\n",
    "\n",
    "def compute_tfidf1(term, doc_id):\n",
    "    tf = sorted_dict[term][doc_id]\n",
    "    idf = math.log2(N / len(sorted_dict[term]))\n",
    "    idf_dict[term]=math.log2(N / len(sorted_dict[term]))\n",
    "    return tf * idf\n",
    "\n",
    "weighted_index = {}\n",
    "for term in sorted_dict:\n",
    "    weighted_index[term] = {}\n",
    "    for doc_id in sorted_dict[term]:\n",
    "        weighted_index[term][doc_id] = compute_tfidf(term, doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1120e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing of the user query.\n",
    "def userquery1(query):\n",
    "    query_idf={}\n",
    "    query=re.sub(r'≥|µ|\\d+', '', query).translate(translator).lower().split()\n",
    "\n",
    "    filtered_words = [word for word in query if word not in stopwords and len(word) > 1]\n",
    "\n",
    "    \n",
    "    stemming = snowball.SnowballStemmer('english')\n",
    "    stemming_wwrds = [stemming.stem(x) for x in filtered_words]\n",
    "    for i in stemming_wwrds:\n",
    "        if i in idf_dict.keys():\n",
    "            query_idf[i]=idf_dict[i]\n",
    "        else:\n",
    "             pass\n",
    "    return query_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5353e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Lenght for all the similarities for the MEdline corpus\n",
    "def doclength1(similarity):\n",
    "    doc_length={}\n",
    "    if similarity.lower()=='cosine':\n",
    "        #for Cosine Similarity\n",
    "        for key, value in sorted_dict.items():\n",
    "            for document in value.keys():\n",
    "                if document not in doc_length:\n",
    "                    doc_length[document]=(sorted_dict[key][document]*idf_dict[key])**2\n",
    "                else:\n",
    "                    doc_length[document]+=(sorted_dict[key][document]*idf_dict[key])**2\n",
    "        for key in doc_length:\n",
    "            doc_length[key] = math.sqrt(doc_length[key])\n",
    "    else:\n",
    "        #for jaccard and dice\n",
    "        for key, value in sorted_dict.items():\n",
    "            for document in value.keys():\n",
    "                if document not in doc_length:\n",
    "                    doc_length[document]=(sorted_dict[key][document]*idf_dict[key])**2\n",
    "                else:\n",
    "                    doc_length[document]+=(sorted_dict[key][document]*idf_dict[key])**2\n",
    "        for key in doc_length:\n",
    "            doc_length[key] = np.sum(doc_length[key])\n",
    "        \n",
    "    return doc_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b1bc9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the query length for the query and respective similarity\n",
    "def querieslength1(q,similarity):\n",
    "    sum_queries_length=0\n",
    "    if similarity.lower()=='cosine':\n",
    "        for key in q:\n",
    "            sum_queries_length+= (idf_dict[key])**2\n",
    "        sum_queries_length=math.sqrt(sum_queries_length)\n",
    "    elif similarity.lower()=='jaccard' or similarity.lower()=='dice':\n",
    "        for key in q:\n",
    "            sum_queries_length+= (idf_dict[key])**2\n",
    "        sum_queries_length=np.sum(sum_queries_length)      \n",
    "    return sum_queries_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2867f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar documents for the query and the document only for the Cosine Similarity\n",
    "def similar_documents1(q):\n",
    "    similarities=[\"Cosine\"]\n",
    "    dictionaries_list=[]\n",
    "    document_ids= list(range(0,len(med_txt_list)))\n",
    "    document_dict = {document: 0 for document in document_ids}\n",
    "    query_length=querieslength1(q,'Cosine')\n",
    "    doc_length=doclength1('Cosine')\n",
    "    for term in q:\n",
    "        for key in sorted_dict[term].keys():\n",
    "            document_dict[key]+=(sorted_dict[term][key]*idf_dict[term])*(1*idf_dict[term])\n",
    "    for key in document_dict:\n",
    "        if key in doclength1('Cosine'):\n",
    "            document_dict[key] = document_dict[key]/(query_length*doc_length[key])\n",
    "\n",
    "    dictionaries_list.append(document_dict)\n",
    " \n",
    "    diff_similarity_df = pd.DataFrame.from_dict(dictionaries_list )\n",
    "    diff_similarity_df=diff_similarity_df.T\n",
    "    diff_similarity_df.columns = similarities\n",
    "    return diff_similarity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "751e1903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [72, 509, 168, 965, 500, 360, 138, 142, 181, 180], 2: [258, 712, 162, 289, 299, 187, 237, 96, 713, 192], 3: [70, 41, 62, 59, 71, 234, 160, 230, 282, 276], 4: [67, 407, 234, 952, 93, 113, 532, 713, 175, 953], 5: [8, 5, 11, 308, 329, 159, 658, 327, 6, 333], 6: [112, 243, 323, 253, 267, 116, 242, 238, 122, 321], 7: [121, 189, 261, 92, 247, 82, 392, 391, 114, 112], 8: [52, 435, 265, 60, 434, 426, 250, 264, 1026, 262], 9: [421, 413, 114, 194, 82, 56, 75, 97, 409, 268], 10: [572, 532, 534, 281, 77, 209, 543, 677, 702, 176], 11: [780, 92, 990, 122, 228, 445, 318, 446, 316, 225], 12: [19, 367, 368, 853, 20, 193, 371, 220, 744, 768], 13: [197, 198, 21, 196, 195, 199, 194, 481, 144, 147], 14: [455, 457, 23, 25, 368, 26, 467, 853, 461, 454], 15: [218, 361, 103, 219, 106, 355, 893, 353, 102, 357], 16: [202, 36, 99, 205, 98, 812, 486, 484, 1012, 253], 17: [41, 336, 38, 472, 128, 216, 342, 129, 379, 528], 18: [521, 528, 526, 45, 134, 49, 81, 548, 517, 525], 19: [847, 844, 555, 440, 32, 507, 441, 564, 563, 596], 20: [878, 603, 596, 581, 873, 577, 585, 880, 1032, 571], 21: [821, 253, 810, 888, 896, 815, 766, 613, 892, 626], 22: [48, 648, 375, 1012, 647, 108, 371, 1011, 758, 905], 23: [849, 917, 804, 798, 916, 819, 813, 620, 817, 812], 24: [667, 941, 674, 852, 686, 850, 853, 670, 851, 668], 25: [698, 687, 699, 696, 305, 948, 679, 695, 691, 930], 26: [737, 716, 75, 383, 89, 637, 47, 404, 138, 88], 27: [736, 739, 734, 977, 735, 984, 732, 731, 728, 911], 28: [791, 780, 774, 779, 776, 448, 789, 997, 607, 81], 29: [1016, 853, 740, 1008, 1017, 1015, 1009, 754, 1013, 22]}\n",
      "Wall time: 17min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the top 10 retrieved documents using Cosine Similarity \n",
    "retrieved_doc={}\n",
    "for key,values in cacm_queries.items():\n",
    "#     print(key)\n",
    "    expanded_query=word2vec_expand(values, num_words=5, threshold=0.5)\n",
    "    q=userquery1(expanded_query)\n",
    "    dftestsim=similar_documents1(q)\n",
    "    retrieved_doc[key]=list(dftestsim.sort_values(by='Cosine' , ascending=False).reset_index().rename(columns={'index':'Document ID'})['Document ID'].iloc[0:10])\n",
    "print(retrieved_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b87674c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant Documents.\n",
    "med_rel_data = open(PATH_TO_MED_REL)\n",
    "med_np = np.loadtxt(med_rel_data, dtype=int)\n",
    "\n",
    "med_rel_rat = defaultdict(list)\n",
    "for row in med_np:\n",
    "    med_rel_rat[row[0]].append(row[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cebd7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection of Relevant and Retrieved Documents\n",
    "def find_matching_values(dict1, dict2):\n",
    "    count = 0\n",
    "    for key1, value1 in dict1.items():\n",
    "        if key1 in dict2:\n",
    "            for val1 in value1:\n",
    "#                 print(val1 ,dict2[key1] )\n",
    "                if val1 in dict2[key1]:\n",
    "                    count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df2d74ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersection of Relevant and Retrieved Documents\n",
    "inte_rel_ret = find_matching_values(retrieved_doc, med_rel_rat)\n",
    "inte_rel_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0547201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    }
   ],
   "source": [
    "# Number of retrieved documents \n",
    "count_retr = 0\n",
    "for values in retrieved_doc.values():\n",
    "    count_retr += len(values)\n",
    "print(count_retr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "27604692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696\n"
     ]
    }
   ],
   "source": [
    "# Number of relevance documents\n",
    "count_rel = 0\n",
    "for values in med_rel_rat.values():\n",
    "    count_rel += len(values)\n",
    "print(count_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "431abfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision for the test data set is 0.6 and the recall is 0.25\n"
     ]
    }
   ],
   "source": [
    "# Calculate Precison and Recall\n",
    "\n",
    "Precision = inte_rel_ret/count_retr\n",
    "\n",
    "Recall = inte_rel_ret/count_rel\n",
    "\n",
    "print(f'The precision for the test data set is {Precision} and the recall is {Recall}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
